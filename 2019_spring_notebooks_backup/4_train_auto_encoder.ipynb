{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Input,Flatten,Dense\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "MEAN_PIXEL = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "\n",
    "\n",
    "def vgg_layers(inputs, target_layer):\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "#     x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "#     x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "#     x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "#     x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    x = Conv2D(1, (3, 3), activation='relu', padding='same', name='downsample')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def VGG19(input_tensor=None, input_shape=None, target_layer=1):\n",
    "    \"\"\"\n",
    "    VGG19, up to the target layer (1 for relu1_1, 2 for relu2_1, etc.)\n",
    "    \"\"\"\n",
    "    if input_tensor is None:\n",
    "        inputs = Input(shape=input_shape)\n",
    "    else:\n",
    "        inputs = Input(tensor=input_tensor, shape=input_shape)\n",
    "    model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19')\n",
    "    # load_weights(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    # Convert 'RGB' -> 'BGR'\n",
    "    if type(x) is np.ndarray:\n",
    "        x = x[..., ::-1]\n",
    "    else:\n",
    "        x = tf.reverse(x, [-1])\n",
    "\n",
    "    return x - MEAN_PIXEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, UpSampling2D\n",
    "\n",
    "def decoder_layers(inputs, layer):\n",
    "\n",
    "    x=decoder_block4(inputs)\n",
    "    x=decoder_block3(x)\n",
    "    x=decoder_block2(x)\n",
    "    x=decoder_block1(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def decoder_block1(inputs):\n",
    "    x = UpSampling2D((2, 2), name='decoder_block1_upsample')(inputs)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='decoder_block1_conv2')(x)\n",
    "#     x = Conv2D(32, (3, 3), activation='relu', padding='same', name='decoder_block1_conv1')(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block2(inputs):\n",
    "    x = UpSampling2D((2, 2), name='decoder_block2_upsample')(inputs)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_block2_conv2')(x)\n",
    "#     x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_block2_conv1')(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block3(inputs):\n",
    "    x = UpSampling2D((2, 2), name='decoder_block3_upsample')(inputs)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_block3_conv3')(x)\n",
    "#     x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_block3_conv2')(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block4(inputs):\n",
    "    x = UpSampling2D((2, 2), name='decoder_block4_upsample')(inputs)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block4_conv3')(x)\n",
    "#     x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block4_conv1')(x)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Conv2D, Input\n",
    "import keras.backend as K\n",
    "\n",
    "LAMBDA=1\n",
    "\n",
    "def l2_loss(x):\n",
    "    return K.sum(K.square(x)) / 2\n",
    "\n",
    "class EncoderDecoder:\n",
    "    def __init__(self, input_shape=(256, 256, 3), target_layer=5,\n",
    "                 decoder_path=None):\n",
    "        self.input_shape = input_shape\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        self.encoder = VGG19(input_shape=input_shape, target_layer=target_layer)\n",
    "        if decoder_path:\n",
    "            self.decoder = load_model(decoder_path)\n",
    "        else:\n",
    "            self.decoder = self.create_decoder(target_layer)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(self.encoder)\n",
    "        self.model.add(self.decoder)\n",
    "\n",
    "        self.loss = self.create_loss_fn(self.encoder)\n",
    "\n",
    "        self.model.compile('adam', self.loss)\n",
    "\n",
    "    def create_loss_fn(self, encoder):\n",
    "        def get_encodings(inputs):\n",
    "            encoder = VGG19(inputs, self.input_shape, self.target_layer)\n",
    "            return encoder.output\n",
    "\n",
    "        def loss(img_in, img_out):\n",
    "            encoding_in = get_encodings(img_in)\n",
    "            encoding_out = get_encodings(img_out)\n",
    "            return l2_loss(img_out - img_in) + \\\n",
    "                   LAMBDA*l2_loss(encoding_out - encoding_in)\n",
    "        return loss\n",
    "\n",
    "    def create_decoder(self, target_layer):\n",
    "        inputs = Input(shape=self.encoder.output_shape[1:])\n",
    "        layers = decoder_layers(inputs, target_layer)\n",
    "        output = Conv2D(3, (3, 3), activation='relu', padding='same',\n",
    "                        name='decoder_out')(layers)\n",
    "        return Model(inputs, output, name='decoder_%s' % target_layer)\n",
    "\n",
    "    def export_decoder(self):\n",
    "        self.decoder.save('decoder_%s.h5' % self.target_layer)\n",
    "\n",
    "    def export_encoder(self):\n",
    "        self.encoder.save('encoder_%s.h5' % self.target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13736 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import Callback\n",
    "from scipy.misc import imresize, imsave\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_PATH = 'totaldata/'\n",
    "TARGET_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "# gen = datagen.flow_from_directory(TRAIN_PATH, target_size=TARGET_SIZE,\n",
    "#                                   batch_size=BATCH_SIZE, class_mode=None)\n",
    "\n",
    "\n",
    "def create_gen(img_dir, target_size, batch_size):\n",
    "    datagen = ImageDataGenerator()\n",
    "    gen = datagen.flow_from_directory(img_dir, target_size=target_size,\n",
    "                                      batch_size=batch_size, class_mode=None)\n",
    "\n",
    "    def tuple_gen():\n",
    "        for img in gen:\n",
    "            if img.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            # (X, y)\n",
    "            yield (img, img)\n",
    "\n",
    "    return tuple_gen()\n",
    "\n",
    "# This needs to be in scope where model is defined\n",
    "class OutputPreview(Callback):\n",
    "    def __init__(self, model, test_img_path, increment, preview_dir_path):\n",
    "        test_img = image.load_img(test_img_path)\n",
    "        test_img = imresize(test_img, (256, 256, 3))\n",
    "        test_target = image.img_to_array(test_img)\n",
    "        test_target = np.expand_dims(test_target, axis=0)\n",
    "        self.test_img = test_target\n",
    "        self.model = model\n",
    "\n",
    "        self.preview_dir_path = preview_dir_path\n",
    "\n",
    "        self.increment = increment\n",
    "        self.iteration = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.iteration % self.increment == 0):\n",
    "            output_img = self.model.predict(self.test_img)[0]\n",
    "            fname = '%d.jpg' % self.iteration\n",
    "            out_path = os.path.join(self.preview_dir_path, fname)\n",
    "            imsave(out_path, output_img)\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "\n",
    "gen = create_gen(TRAIN_PATH, TARGET_SIZE, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "downsample (Conv2D)          (None, 16, 16, 1)         2305      \n",
      "=================================================================\n",
      "Total params: 390,721\n",
      "Trainable params: 390,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 16, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "decoder_block4_upsample (UpS (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "decoder_block4_conv3 (Conv2D (None, 32, 32, 256)       2560      \n",
      "_________________________________________________________________\n",
      "decoder_block3_upsample (UpS (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "decoder_block3_conv3 (Conv2D (None, 64, 64, 128)       295040    \n",
      "_________________________________________________________________\n",
      "decoder_block2_upsample (UpS (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "decoder_block2_conv2 (Conv2D (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "decoder_block1_upsample (UpS (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "decoder_block1_conv2 (Conv2D (None, 256, 256, 32)      18464     \n",
      "_________________________________________________________________\n",
      "decoder_out (Conv2D)         (None, 256, 256, 3)       867       \n",
      "=================================================================\n",
      "Total params: 390,723\n",
      "Trainable params: 390,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_samples = 13736 \n",
    "epochs = 12\n",
    "steps_per_epoch = num_samples // BATCH_SIZE\n",
    "\n",
    "target_layer = 3\n",
    "\n",
    "encoder_decoder = EncoderDecoder(target_layer=target_layer)\n",
    "encoder_decoder.encoder.summary()\n",
    "encoder_decoder.decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "   4/1717 [..............................] - ETA: 26:11 - loss: 5459878720.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/conda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.116091). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717/1717 [==============================] - 98s 57ms/step - loss: 628994063.7857\n",
      "Epoch 2/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 432643444.4636\n",
      "Epoch 3/12\n",
      "1717/1717 [==============================] - 95s 55ms/step - loss: 416362782.5649\n",
      "Epoch 4/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 396266352.5498\n",
      "Epoch 5/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 385696179.9977\n",
      "Epoch 6/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 378967053.4188\n",
      "Epoch 7/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 372956194.5906\n",
      "Epoch 8/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 367196470.1223\n",
      "Epoch 9/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 363338561.5842\n",
      "Epoch 10/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 360235008.3541\n",
      "Epoch 11/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 358356738.5253\n",
      "Epoch 12/12\n",
      "1717/1717 [==============================] - 94s 55ms/step - loss: 353917042.2085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "callbacks = [OutputPreview(encoder_decoder, './1.jpg', 800, 'out' )]\n",
    "encoder_decoder.model.fit_generator(gen, steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs, callbacks=callbacks)\n",
    "encoder_decoder.export_decoder()\n",
    "encoder_decoder.export_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
