{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,GlobalMaxPooling1D,MaxPooling1D\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D,AveragePooling1D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import average \n",
    "from keras.models import Input, Model\n",
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.io import imshow\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we can see what does the feature look like\n",
    "def get_raw_feature():\n",
    "    video_data_dir='C:\\\\new_video_feature\\\\'\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for video in os.listdir(video_data_dir):\n",
    "        each_video= pjoin(video_data_dir,video)\n",
    "        ## 'C:\\\\videofeature\\\\' using\n",
    "#         l=each_video.split('t_')[1]\n",
    "\n",
    "        # 'C:\\\\new_video_feature\\\\' using\n",
    "        l=each_video.split('e_')[1]\n",
    "        l=l.split('.')[0]\n",
    "        LABEL=int(l)\n",
    "        X.append(np.load(each_video))\n",
    "        Y.append(LABEL)\n",
    "    Video_label=pd.read_csv('label.csv')\n",
    "    Video_label=np.array(Video_label)[:,:-1]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Read features from 19 npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  19 videos\n",
      "feature of video [0] (739, 14)\n",
      "video [0] is from video 1\n",
      "[1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "X,Y=get_raw_feature()\n",
    "Video_label=pd.read_csv('label.csv')\n",
    "Video_label=np.array(Video_label)[:,:-1]\n",
    "print('there are ',len(X),'videos')\n",
    "print('feature of video [0]',X[0].shape)\n",
    "print('video [0] is from video' ,Y[0])\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video_label contains detail labels and we can use Y to index them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33, 1.67, 1.  , 1.67, 1.33, 1.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [1.67, 1.  , 1.  , 1.67, 1.33, 1.33],\n",
       "       [4.33, 4.33, 4.33, 4.33, 5.  , 4.67],\n",
       "       [2.33, 1.67, 2.  , 2.  , 3.  , 2.33],\n",
       "       [3.33, 3.33, 2.67, 3.33, 4.  , 3.67],\n",
       "       [4.67, 4.  , 4.  , 4.67, 5.  , 4.67],\n",
       "       [2.  , 2.  , 1.33, 1.  , 1.33, 2.33],\n",
       "       [1.33, 1.67, 1.33, 1.33, 1.  , 1.67],\n",
       "       [2.67, 2.67, 2.67, 2.33, 3.33, 3.  ],\n",
       "       [1.33, 1.67, 1.  , 1.33, 2.  , 1.33],\n",
       "       [2.67, 2.67, 1.67, 2.67, 2.67, 2.33],\n",
       "       [3.67, 3.33, 3.  , 3.  , 3.67, 3.33],\n",
       "       [1.67, 2.  , 1.  , 1.67, 1.67, 2.  ],\n",
       "       [5.  , 5.  , 5.  , 4.67, 5.  , 4.67],\n",
       "       [1.33, 1.  , 1.33, 1.  , 1.  , 1.67],\n",
       "       [1.67, 1.67, 1.  , 2.  , 2.33, 1.67],\n",
       "       [4.33, 4.33, 4.  , 4.  , 4.33, 4.33],\n",
       "       [4.  , 3.  , 3.  , 4.5 , 4.  , 4.  ],\n",
       "       [4.  , 3.5 , 4.5 , 4.  , 4.5 , 4.5 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create two functions to sample video clips from each video and get their time differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_and_hstack_to_orginal_data(X,time_lag=2,move_threshold=200):\n",
    "    original=X[:-time_lag]\n",
    "    modified=X[time_lag:]\n",
    "    result=modified-original\n",
    "    ## threshold\n",
    "    # consider there was no top in the first image and it showed up in the next image\n",
    "    # the difference would be huge, which was not ideal.\n",
    "    # so we need to filter these extrem value \n",
    "    result[np.abs(result)>move_threshold]=0\n",
    "    \n",
    "    return np.hstack((X[time_lag:],result))\n",
    "\n",
    "##from each video sample video clips with size=window_L. you can specify stride \n",
    "def make_video_clips(matrix,window_L,stride):\n",
    "    alldata=[]\n",
    "\n",
    "    total_frame=matrix.shape[0]\n",
    "    index=[n for n in range(1,total_frame,stride)]\n",
    "    for start_index in index:\n",
    "        if start_index+window_L> total_frame:\n",
    "            break\n",
    "#         print(start_index)\n",
    "        each_clip_data=matrix[start_index:start_index+window_L]\n",
    "        each_clip_data=np.transpose(each_clip_data)\n",
    "#         print(each_clip_data.shape)\n",
    "        alldata.append(each_clip_data)\n",
    "    return np.array(alldata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 pre-processing the feature\n",
    "make new 28-d feature and  sample video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 28, 30)\n",
      "(32, 28, 30)\n",
      "(25, 28, 30)\n",
      "(24, 28, 30)\n",
      "(21, 28, 30)\n",
      "(24, 28, 30)\n",
      "(16, 28, 30)\n",
      "(24, 28, 30)\n",
      "(24, 28, 30)\n",
      "(24, 28, 30)\n",
      "(22, 28, 30)\n",
      "(20, 28, 30)\n",
      "(26, 28, 30)\n",
      "(24, 28, 30)\n",
      "(24, 28, 30)\n",
      "(24, 28, 30)\n",
      "(22, 28, 30)\n",
      "(24, 28, 30)\n",
      "(25, 28, 30)\n"
     ]
    }
   ],
   "source": [
    "####################################### set video clips parameters\n",
    "############################################### make new 28-d feature\n",
    "video_clips_length=30\n",
    "time_lag=1\n",
    "move_threshold=150\n",
    "stride=int(video_clips_length)\n",
    "\n",
    "####################################### set video clips parameters\n",
    "############################################### make new 28-d feature\n",
    "all_data=[]\n",
    "for each_video,label in zip(X,Y):\n",
    "\n",
    "    re=get_diff_and_hstack_to_orginal_data(each_video,time_lag,move_threshold)\n",
    "    video_clip=make_video_clips(re,video_clips_length,stride)\n",
    "    print(video_clip.shape)\n",
    "    all_data.append((video_clip))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 19 videos and you can see how many video clips they have.\n",
    "\n",
    "And next we will use leave one method to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 prepare leave one data and give every video clips their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to stack 18 videos into a big matrix\n",
    "# the dimenstion will be \n",
    "# (n1+n2..+n18,28,30)\n",
    "# and the label will be (n1+n2..+n18,6)\n",
    "\n",
    "def stack_video_clips_get_label(data,label):\n",
    "    final_data=data[0]\n",
    "    final_label=[label[0] for _ in range(final_data.shape[0])]\n",
    "    for i in range(1,len(data)):\n",
    "        final_data=np.vstack((final_data,data[i]))\n",
    "        for j in range(data[i].shape[0]):\n",
    "            final_label.append(label[i])\n",
    "    return final_data,final_label\n",
    "\n",
    "########## leave one and stack all video clips\n",
    "def hold_out(X,Y,hold_number):\n",
    "        new_label=Y.copy()\n",
    "        new_data=X.copy()\n",
    "        # find video n 's index\n",
    "        index=new_label.index(hold_number)\n",
    "        # get the video n and it's label\n",
    "        X_test=new_data[index]\n",
    "        hold_number_label=np.array([hold_number for _ in range(X_test.shape[0])])\n",
    "        y_test=Video_label[hold_number_label-1]\n",
    "        # so we can del them \n",
    "        del new_label[index]\n",
    "        del new_data[index]\n",
    "\n",
    "        final_data_X,final_data_Y=stack_video_clips_get_label(new_data,new_label)\n",
    "        \n",
    "        final_data_Y=np.array(final_data_Y)\n",
    "        # the label of video 1 is Video_label[0]. \n",
    "        final_data_Y=Video_label[final_data_Y-1]\n",
    "        return final_data_X,X_test,final_data_Y,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized data generator\n",
    "def generator(data, label, batch_size=128):\n",
    "    while 1:\n",
    "        rows = np.random.randint(0, data.shape[0], size=batch_size)\n",
    "        samples = data[rows]\n",
    "        y=label[rows]\n",
    "        yield samples,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each col, calculate the weighted average\n",
    "def get_weighted_average(df):\n",
    "    length=len(df)\n",
    "    top=int(1/6*length)\n",
    "    bottom=length-top\n",
    "    df=np.array(df)\n",
    "    df=np.sort(df)\n",
    "    weghted_sum=np.sum(df[:top]*(1/6))+np.sum(df[top+1:bottom]*(2/3))+np.sum(df[bottom+1:]*(1/6))\n",
    "    weghted_sum=weghted_sum/length\n",
    "    return weghted_sum\n",
    "\n",
    "# make the data frame\n",
    "# Plot_data is the pridect result, which will have 6 scores\n",
    "def get_video_score(Plot_data,GT):\n",
    "    weight_ave_re=[]\n",
    "    mean_re=[]\n",
    "    median_re=[]\n",
    "    pooled_re=[]\n",
    "    \n",
    "    for i in Plot_data.columns:\n",
    "        weight_ave=get_weighted_average(Plot_data[i])\n",
    "        weight_ave_re.append(weight_ave)\n",
    "        \n",
    "        mean_value=np.mean(Plot_data[i])   \n",
    "        mean_re.append(mean_value)\n",
    "        \n",
    "        median_value = np.median(Plot_data[i])\n",
    "        median_re.append(median_value)\n",
    "        \n",
    "        # pooling is also a weighted average \n",
    "        pooling = (weight_ave*0.2 + mean_value*0.2 + median_value*0.6)\n",
    "        \n",
    "        pooled_re.append(pooling)\n",
    "        \n",
    "    video_result=pd.DataFrame([weight_ave_re,mean_re,median_re,pooled_re,GT])\n",
    "    video_result.columns = ['DP','BD','E','FS','A','RC']\n",
    "    video_result.index = ['Weighted_average', 'Mean', 'Median','Cool_pooling','Ground_truth']\n",
    "    return video_result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 perform leave one cross validation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model we will use\n",
    "def make_model_1d(l2_lambda,clip_lenth,dimension):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, \n",
    "                     kernel_size=10, \n",
    "                     padding='same',\n",
    "                     activation='relu', \n",
    "                     input_shape=(clip_lenth, dimension),\n",
    "                     kernel_regularizer=l2(l2_lambda)))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, \n",
    "                     kernel_size=10, \n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     kernel_regularizer=l2(l2_lambda)))\n",
    "    \n",
    "    model.add(MaxPooling1D(3,\n",
    "                          padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=128, \n",
    "                     kernel_size=5, \n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     kernel_regularizer=l2(l2_lambda)))\n",
    "    model.add(Conv1D(filters=128, \n",
    "                     kernel_size=5, \n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     kernel_regularizer=l2(l2_lambda)))\n",
    "    \n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', # 'categorical_crossentropy' 'mean_squared_error' 'mean_absolute_percentage_error'\n",
    "              optimizer='adam', # 'adadelta' 'rmsprop'\n",
    "              )\n",
    "    # model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hold_out(hold_out_number,show_result=False):\n",
    "    # using leave one cv to get train/test data\n",
    "    X_train, X_test, y_train, y_test=hold_out(all_data,Y,hold_out_number)\n",
    "    \n",
    "    # scale all the value to 0-1\n",
    "    X_train=X_train/640\n",
    "    X_test=X_test/640\n",
    "    y_train=y_train/5\n",
    "    y_test=y_test/5\n",
    "    # print(X_train.shape,y_train.shape)\n",
    "    # print(X_test.shape,y_test.shape)\n",
    "\n",
    "    sample_of_trainningdata=X_train.shape[0]\n",
    "    sample_of_testdata=X_test.shape[0]\n",
    "\n",
    "\n",
    "    batch_size=128\n",
    "    l2=0.004\n",
    "\n",
    "\n",
    "    train_gen=generator(X_train, y_train, batch_size)\n",
    "    val_gen=generator(X_test, y_test, batch_size)\n",
    "    \n",
    "    #prepare for inout shape\n",
    "    clip_lenth=X_train.shape[1]\n",
    "    dimension=X_train.shape[2]\n",
    "    \n",
    "    #make cnn 1d\n",
    "    cnn1d=make_model_1d(l2,clip_lenth,dimension)\n",
    "    cnn1d_h=cnn1d.fit_generator(train_gen,\n",
    "                        steps_per_epoch=int(sample_of_trainningdata/batch_size),\n",
    "                        epochs=40,\n",
    "                        validation_data=val_gen,\n",
    "                       validation_steps=1,\n",
    "                        verbose=0 )\n",
    "    \n",
    "    if show_result:\n",
    "        ax=plt.figure(figsize=(10,6))\n",
    "        ax = plt.subplot(221)\n",
    "        ax.plot(cnn1d_h.history['loss'])\n",
    "        plt.ylabel('Training Loss')\n",
    "        plt.xlabel('epochs')\n",
    "\n",
    "        ax = plt.subplot(222)\n",
    "        ax.plot(cnn1d_h.history['val_loss'])\n",
    "        plt.ylabel('valadation Loss')\n",
    "        plt.xlabel('epochs')\n",
    "\n",
    "        print('loss',cnn1d_h.history['val_loss'][-1])\n",
    "\n",
    "        GT=list(Video_label[hold_out_number-1])\n",
    "\n",
    "        #get pridect result\n",
    "        predict=cnn1d.predict(X_test)\n",
    "        re=predict*5\n",
    "        Plot_data=pd.DataFrame(re,columns=['DP','BD','E','FS','A','RC'])\n",
    "        video_result=get_video_score(Plot_data,GT)\n",
    "        print(video_result)\n",
    "\n",
    "        y=[x for x in range(1,7)]\n",
    "        ax = plt.subplot(223)\n",
    "        gt=video_result.iloc[4]\n",
    "        re=video_result.iloc[3]\n",
    "        ax.plot(y, re, label='predict')\n",
    "        ax.plot(y, gt, label='ground truth')\n",
    "        plt.ylim(0,5.5)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "    return cnn1d_h.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y)\n",
    "# print(\"you can try the video number above\")\n",
    "# test_hold_out(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# un-comment the code blow to test all the video\n",
    "# total_loss=0\n",
    "# show_result=False\n",
    "# for i in Y:\n",
    "#     print('video',i)\n",
    "#     loss=test_hold_out(i,show_result)\n",
    "#     total_loss=total_loss+loss\n",
    "# print('total_loss= ',total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_clips_length 30  time_lag 1 move_threshold 100 stride 30\n",
      "total_loss=  1.412462801206857\n",
      "video_clips_length 30  time_lag 1 move_threshold 100 stride 15\n",
      "total_loss=  1.4150967202149332\n",
      "video_clips_length 30  time_lag 1 move_threshold 200 stride 30\n",
      "total_loss=  1.397022263146937\n",
      "video_clips_length 30  time_lag 1 move_threshold 200 stride 15\n",
      "total_loss=  1.4331296226009727\n",
      "video_clips_length 30  time_lag 2 move_threshold 100 stride 30\n",
      "total_loss=  1.3969617546536028\n",
      "video_clips_length 30  time_lag 2 move_threshold 100 stride 15\n",
      "total_loss=  1.4400804012548178\n",
      "video_clips_length 30  time_lag 2 move_threshold 200 stride 30\n",
      "total_loss=  1.3962573492899537\n",
      "video_clips_length 30  time_lag 2 move_threshold 200 stride 15\n",
      "total_loss=  1.425527356332168\n",
      "video_clips_length 60  time_lag 1 move_threshold 100 stride 60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3ae3a9a4eaab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#                     print('video',i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_hold_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                     \u001b[0mtotal_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total_loss= '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-ca46f3343dab>\u001b[0m in \u001b[0;36mtest_hold_out\u001b[1;34m(hold_out_number, show_result)\u001b[0m\n\u001b[0;32m     33\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                        \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                         verbose=0 )\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshow_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                             workers=0)\n\u001b[0m\u001b[0;32m    235\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                         \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                  \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                                  str(generator_output))\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2671\u001b[1;33m                                 session)\n\u001b[0m\u001b[0;32m   2672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2622\u001b[0m         \u001b[1;31m# Create callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2623\u001b[1;33m         \u001b[0mcallable_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2624\u001b[0m         \u001b[1;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2625\u001b[0m         \u001b[1;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \"\"\"\n\u001b[0;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session, callable_options)\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[1;32m-> 1425\u001b[1;33m               session._session, options_ptr, status)\n\u001b[0m\u001b[0;32m   1426\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################### set video clips parameters\n",
    "############################################### make new 28-d feature\n",
    "video_clips_length=[30,60]\n",
    "time_lag=[1,2]\n",
    "move_threshold=[100,200]\n",
    "# stride=int(video_clips_length)\n",
    "\n",
    "####################################### set video clips parameters\n",
    "############################################### make new 28-d feature\n",
    "\n",
    "for vl in video_clips_length:\n",
    "    for tl in time_lag:\n",
    "        for mt in move_threshold:\n",
    "            S=[int(vl),int(vl/2)]\n",
    "            for stride in S:\n",
    "                print('video_clips_length',vl,' time_lag',tl,'move_threshold',mt,'stride',stride)\n",
    "\n",
    "                all_data=[]\n",
    "                \n",
    "                for each_video,label in zip(X,Y):\n",
    "\n",
    "                    re=get_diff_and_hstack_to_orginal_data(each_video,tl,mt)\n",
    "                    video_clip=make_video_clips(re,vl,stride)\n",
    "    #                 print(video_clip.shape)\n",
    "                    all_data.append((video_clip))\n",
    "        \n",
    "                total_loss=0\n",
    "                show_result=False\n",
    "                for i in Y:\n",
    "#                     print('video',i)\n",
    "                    loss=test_hold_out(i,show_result)\n",
    "                    total_loss=total_loss+loss\n",
    "                print('total_loss= ',total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_clips_length 30  time_lag 1 move_threshold 100 stride 30\n",
    "# total_loss=  1.412462801206857\n",
    "# video_clips_length 30  time_lag 1 move_threshold 100 stride 15\n",
    "# total_loss=  1.4150967202149332\n",
    "# video_clips_length 30  time_lag 1 move_threshold 200 stride 30\n",
    "# total_loss=  1.397022263146937\n",
    "# video_clips_length 30  time_lag 1 move_threshold 200 stride 15\n",
    "# total_loss=  1.4331296226009727\n",
    "# video_clips_length 30  time_lag 2 move_threshold 100 stride 30\n",
    "# total_loss=  1.3969617546536028\n",
    "# video_clips_length 30  time_lag 2 move_threshold 100 stride 15\n",
    "# total_loss=  1.4400804012548178\n",
    "# video_clips_length 30  time_lag 2 move_threshold 200 stride 30\n",
    "# total_loss=  1.3962573492899537\n",
    "# video_clips_length 30  time_lag 2 move_threshold 200 stride 15\n",
    "# total_loss=  1.425527356332168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
