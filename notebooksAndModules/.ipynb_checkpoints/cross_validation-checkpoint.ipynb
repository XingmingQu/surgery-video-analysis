{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import an awesome Label helper\n",
      "import an awesome feature helper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import modules.labelHelper as lh \n",
    "import modules.featureHelper as fh\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Conv1D, GlobalAveragePooling1D, MaxPooling1D,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,average, concatenate,RepeatVector,Lambda,add,subtract,Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Input, Model\n",
    "from sklearn import metrics as mt\n",
    "from skimage.io import imshow\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.ndimage import maximum_filter1d\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "warnings.filterwarnings('ignore')\n",
    "from modules.modelTools import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from modules.plotHelper import *\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.ndimage import maximum_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 videos in total\n",
      "\n",
      "There are 19 trainees in total\n",
      "\n",
      " Number of Videos from each person\n",
      "Akhtar          -- [176 253 761] ----: 3\n",
      "Cadeddu         -- [164 171] ----: 2\n",
      "Crivelli        -- [225 276 333 425] ----: 4\n",
      "Gahan           -- [257 345 378 384 486] ----: 5\n",
      "Johnson         -- [441 615] ----: 2\n",
      "Keith           -- [240 277 717] ----: 3\n",
      "Kenigsberg      -- [ 78 440 455 471 881] ----: 5\n",
      "Krabbe          -- [152 344 527 861] ----: 4\n",
      "Marthur         -- [130 194 222 368 921] ----: 5\n",
      "Mollengarden    -- [ 59 143 267 460] ----: 4\n",
      "Moony           -- [294 301 361 498 539] ----: 5\n",
      "Passoni         -- [207 237 895 942] ----: 4\n",
      "Rozanski        -- [113 302 716] ----: 3\n",
      "Satyanarayan    -- [ 16  74 236 358 436 457 503 537 557 578 599 632 689] ----: 13\n",
      "Singla          -- [ 49 536 538] ----: 3\n",
      "Sorokin         -- [ 91 226 507 530] ----: 4\n",
      "Timburlake      -- [258 296 559 742] ----: 4\n",
      "Tse             -- [ 11 283 414 427 562 928] ----: 6\n",
      "Varun           -- [192 401 417 820] ----: 4\n"
     ]
    }
   ],
   "source": [
    "ll=lh.Label('../2019_fall_labels.csv')\n",
    "print(\"There are %d videos in total\\n\"%ll.video_count())\n",
    "ll.get_trainee_info()\n",
    "\n",
    "train_fold,test_fold=ll.cross_validation_on_people(5)\n",
    "# print(train_fold)\n",
    "# print(test_fold)\n",
    "\n",
    "## set up feature parameters ##\n",
    "folder = \"../2019_fall_video_features\"\n",
    "video_clips_length=30\n",
    "time_lag=2\n",
    "move_threshold=150\n",
    "stride=video_clips_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 1\n",
      "\n",
      "load feature from files, there are 69 videos\n",
      "after deop:  69\n",
      "load feature from files, there are 14 videos\n",
      "after deop:  14\n",
      "(2237, 30, 28)\n",
      "(2237, 6)\n",
      "(465, 30, 28)\n",
      "(465, 6)\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.79906, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.79906 to 1.38146, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.38146 to 0.95771, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.95771 to 0.72322, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72322 to 0.63168, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.63168 to 0.58665, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.58665\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58665\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.58665 to 0.57357, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57357\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57357\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.57357 to 0.53228, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53228 to 0.49731, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.49731\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.49731\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.49731\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.49731 to 0.44280, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.44280\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.44280\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.44280\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[2.6745372  2.4011421  2.2059586  2.101211   3.025496   2.1753476 ]\n",
      " [3.213109   2.9175928  2.4685233  2.461214   3.0595577  2.5980005 ]\n",
      " [3.2361598  3.0616374  1.9648037  2.3641331  3.0434535  2.3652928 ]\n",
      " [3.530998   3.2703166  2.8436255  2.7920198  3.4564974  3.046649  ]\n",
      " [3.5287187  2.9493284  2.7057061  2.6727047  3.4280577  3.0770783 ]\n",
      " [3.087799   2.5434542  2.2933462  2.447243   2.9099917  2.8839183 ]\n",
      " [2.7024655  2.5469408  2.1592963  2.1571174  2.7779713  2.5949633 ]\n",
      " [3.0643857  2.8029335  2.0260031  2.294564   3.0711622  2.6313052 ]\n",
      " [3.4906106  2.9751027  2.737833   2.693753   3.0808659  2.5233028 ]\n",
      " [2.9295745  2.9874408  2.5367374  2.4083188  3.0286052  2.796854  ]\n",
      " [3.0850253  2.7062888  2.166774   2.746191   3.315942   3.2330716 ]\n",
      " [2.9337754  2.5043085  2.6725078  2.4797792  2.9481554  2.3796024 ]\n",
      " [3.0982401  2.7878118  2.3538446  2.4626403  3.267032   2.9328303 ]\n",
      " [3.1262016  3.0923164  2.5210392  1.9377055  2.932312   2.7532682 ]\n",
      " [2.9741     3.132428   2.0250423  2.3958373  2.5863812  2.3145268 ]\n",
      " [2.356192   1.2990501  1.553781   2.3124967  2.1264565  0.5944679 ]\n",
      " [1.9854445  0.         0.38704926 0.         2.2095237  0.25601447]\n",
      " [3.1073358  2.9327297  2.5146823  2.5528407  3.247518   2.7846546 ]\n",
      " [3.093898   3.1509995  2.5756578  2.598283   3.104467   2.7316613 ]\n",
      " [2.9038131  2.4651904  2.034063   2.3320804  2.9626565  2.5354629 ]\n",
      " [2.6307428  2.849433   1.867715   2.2885287  2.6923404  2.7235975 ]\n",
      " [2.805058   2.5539935  2.0858736  2.1075983  2.8365302  2.295727  ]\n",
      " [3.4674373  2.921297   2.63718    2.499994   3.1931515  2.7587743 ]\n",
      " [3.0359392  2.8522694  2.1141334  2.5155396  2.7391167  2.278744  ]\n",
      " [3.0662358  2.726053   2.5849035  2.1323738  3.1503665  2.498295  ]\n",
      " [2.9212933  2.8636825  3.0698106  2.0851061  3.2202668  2.5419867 ]\n",
      " [0.88094366 0.         0.         0.         2.2708132  0.        ]\n",
      " [2.5996904  2.7531078  2.0318391  2.3886209  3.022063   1.8591143 ]\n",
      " [2.9479675  3.00501    2.9730237  2.4612918  3.1620345  2.4608307 ]\n",
      " [2.9696274  2.7054763  2.2947812  2.2566311  2.8904314  1.9955287 ]\n",
      " [2.8210125  2.8637888  2.2513676  2.2978673  3.1737046  2.4259427 ]\n",
      " [1.773987   2.5594325  1.8258483  1.9292881  1.9588492  1.1189067 ]\n",
      " [3.4242802  2.9783416  2.605978   2.8624763  3.552763   2.9218876 ]\n",
      " [3.2694798  3.2152665  2.663865   2.852577   3.1999664  3.5042286 ]\n",
      " [2.8222938  2.5545266  2.3605635  2.3805163  2.8998022  2.472831  ]\n",
      " [2.870697   2.7863657  2.373848   2.2642744  2.9956555  2.40703   ]\n",
      " [2.5229537  2.244625   2.1695976  2.130566   2.2422636  0.83543694]\n",
      " [2.7937496  0.6853393  1.1271737  2.9576995  2.6008039  1.6801817 ]\n",
      " [2.6321807  2.8248653  2.394392   1.8128695  3.0171232  1.9163499 ]\n",
      " [2.417735   2.158322   2.0449278  2.2753026  2.5313134  1.7246339 ]\n",
      " [2.8126874  2.7539062  2.0404198  2.374077   2.961791   2.6228924 ]\n",
      " [2.696547   2.4004571  1.9357835  2.206296   2.8301663  2.3077111 ]\n",
      " [2.4174297  2.572493   1.5553932  2.0629606  2.5899909  2.0367012 ]\n",
      " [3.0572913  2.6072984  2.337351   2.6002684  3.086359   2.6015544 ]\n",
      " [3.2691574  2.1228764  2.6820378  2.1178932  2.946762   2.0711064 ]\n",
      " [2.8796015  2.824881   2.7104533  2.2148542  2.5452158  1.7636924 ]\n",
      " [3.153856   2.3557422  2.180672   2.9053938  3.2359228  2.5549126 ]\n",
      " [2.2179463  2.2651923  2.1343813  2.0305076  2.5208573  2.4538074 ]\n",
      " [2.6505709  0.79358166 1.4292243  2.2345881  2.5331304  1.2497226 ]\n",
      " [2.6798651  2.8227468  2.256954   2.25577    2.581738   2.0821009 ]\n",
      " [3.0894017  3.0843914  2.3414283  2.8344889  3.1108837  2.8046858 ]\n",
      " [3.1171691  2.6062136  2.3323362  2.7162824  3.0966399  2.667302  ]\n",
      " [2.710318   2.6069045  1.6062622  2.4717226  2.1965978  1.9043589 ]\n",
      " [2.6271515  2.464281   2.4071214  2.6671636  2.651161   1.5969405 ]\n",
      " [3.1655502  2.9107027  2.7064795  2.7880397  3.487066   3.0313504 ]\n",
      " [2.6940365  1.9712889  2.2515683  2.9860857  2.672528   0.70364535]\n",
      " [2.1220553  0.         0.5138265  0.03060222 2.413235   0.        ]\n",
      " [4.052564   3.7937164  3.3783026  3.654254   4.226375   3.4512753 ]\n",
      " [1.2640951  0.         0.         0.         2.0287669  0.        ]\n",
      " [2.4078825  2.770843   1.9705104  2.1967678  2.435745   1.5878987 ]\n",
      " [3.3492506  2.9821234  2.5098422  2.8643572  3.5812182  3.4319246 ]\n",
      " [3.1326091  3.0122833  2.2671413  2.8358722  3.1343188  3.198245  ]\n",
      " [3.2906194  3.051188   2.7440999  2.0374362  3.0285013  2.683239  ]\n",
      " [3.0524917  2.3519044  2.345869   2.2788014  3.117391   2.599122  ]\n",
      " [3.428074   3.0095599  2.8236187  2.4418507  3.0677142  2.81424   ]\n",
      " [2.80646    2.6908226  2.410243   2.5725794  2.990925   2.5744321 ]\n",
      " [2.9450095  2.0893173  2.2754903  2.4523933  2.9330244  2.5753665 ]\n",
      " [3.2015755  2.7316082  2.7850091  2.6546767  3.283893   2.886674  ]\n",
      " [3.1168714  2.7973118  2.671692   2.614789   3.308723   2.716527  ]\n",
      " [3.3744054  3.19097    2.7662227  2.7427983  3.277635   3.178629  ]\n",
      " [3.375733   3.0509968  2.6710904  2.669939   3.4383368  2.8820448 ]\n",
      " [3.2253337  2.4271677  2.3878927  2.2699497  3.0204353  2.4893394 ]\n",
      " [3.4974236  3.3949237  3.0030055  2.801132   3.5171514  3.1839964 ]\n",
      " [3.3329468  2.902967   2.587109   2.4826686  3.1661038  2.9284666 ]\n",
      " [3.266616   2.1971598  2.2566903  2.4480383  2.6681209  2.6960778 ]\n",
      " [2.728364   2.7185888  2.426791   2.2398026  3.0065556  2.0673182 ]\n",
      " [3.49087    3.0416102  2.9291382  2.8652859  3.3477545  2.7446556 ]\n",
      " [2.897355   2.683462   1.9985186  2.1040561  2.7443485  2.3720977 ]\n",
      " [2.771223   2.9464772  2.2009423  2.2488017  3.2521968  1.6924596 ]\n",
      " [2.9995914  2.8983068  2.1232839  2.5905232  3.3495271  2.7581155 ]\n",
      " [3.5035493  2.984494   2.5246925  2.0536325  3.254084   2.5677543 ]\n",
      " [2.5467157  2.2537494  2.5000968  1.9610864  2.626411   2.3871593 ]\n",
      " [2.823184   2.5833135  2.0582879  2.2570465  2.8942304  2.4498322 ]\n",
      " [3.5196528  4.373612   3.4643173  2.5050802  3.6670594  3.5812807 ]\n",
      " [3.1226048  0.78495276 0.54578173 2.4471097  2.5052996  1.1342942 ]\n",
      " [3.0074096  2.577847   2.1781619  2.5521672  3.174264   2.3380191 ]\n",
      " [3.15337    3.3521094  2.8993976  2.727778   3.0672696  3.1948705 ]\n",
      " [3.2436924  3.1364381  2.336122   2.9089088  3.331698   2.8167167 ]\n",
      " [3.4830916  3.3938813  3.0401587  2.9026115  3.2754457  3.1261313 ]\n",
      " [3.5947514  3.2077951  3.2415361  3.0398488  3.6792302  3.391358  ]\n",
      " [3.9536495  3.8011909  3.6064944  3.2587316  4.040895   3.7611003 ]\n",
      " [3.768814   3.3973658  3.4798717  3.1418877  3.781625   3.820006  ]\n",
      " [3.9227214  3.7339978  3.3835254  3.3353786  3.7930293  3.4527202 ]\n",
      " [3.6372323  3.0381632  2.7864408  2.8543062  3.6083827  3.2944088 ]\n",
      " [3.4845138  3.4142482  3.303727   3.1896937  3.6348653  3.5438643 ]\n",
      " [3.8157356  3.6862254  3.6411142  3.3191938  4.1156416  3.8009791 ]\n",
      " [2.9789543  2.5091333  2.0626578  2.115262   2.9193532  2.3612664 ]\n",
      " [2.7384756  2.4208229  2.0409503  2.1157045  2.9415247  2.5334144 ]\n",
      " [2.7054822  2.5075386  2.2304814  2.1700385  2.9053288  2.1845458 ]\n",
      " [3.752923   3.1603332  2.407093   2.717111   3.468122   3.051884  ]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[2.9582067  2.917752   2.4456825  2.4489589  3.0306349  2.5563579 ]\n",
      " [2.9730554  2.6741214  2.4493253  2.0990682  2.9080105  2.3043432 ]\n",
      " [3.1474159  2.6310446  2.2884002  2.369803   3.063418   2.4013631 ]\n",
      " [3.075037   2.3987994  2.1727998  2.7120686  2.8850605  2.624442  ]\n",
      " [2.917645   2.8751707  2.272701   2.4486551  3.0344672  2.8263447 ]\n",
      " [3.5987196  4.8085384  2.9047205  2.7419763  3.0440707  3.6158803 ]\n",
      " [1.1750139  0.         0.06697953 0.5180344  1.9745947  0.18292412]\n",
      " [2.6868393  2.6134827  2.3387172  2.1496055  2.7550104  2.1736002 ]\n",
      " [2.8635912  4.300891   2.7654395  2.3935351  3.4840393  3.4972289 ]\n",
      " [2.8719158  2.2781112  2.2739615  2.2289948  2.7189965  2.400106  ]\n",
      " [2.961024   2.2487175  2.2411559  2.0935736  3.0448647  2.2633708 ]\n",
      " [2.3389807  2.633708   1.9172978  2.0803742  2.282448   1.6667598 ]\n",
      " [3.868733   3.6117964  3.0780065  3.11981    3.7976456  3.3101602 ]\n",
      " [3.1340334  2.8921378  2.2106218  2.3447168  3.1568813  2.8109684 ]\n",
      " [2.916751   2.6976638  2.4186826  2.276522   2.907977   2.446464  ]\n",
      " [2.9684174  2.8709679  2.5153604  2.6285112  3.0646896  2.7946866 ]\n",
      " [2.5176084  2.058513   2.0312834  2.1253977  2.2889733  0.9708515 ]\n",
      " [0.6426983  0.         0.         0.         2.3388457  0.        ]\n",
      " [2.7198462  2.3332522  2.5498247  2.0738893  2.8759074  1.8071384 ]\n",
      " [2.9227643  2.8301306  2.391283   2.4759839  2.6855266  2.6111698 ]\n",
      " [2.7149332  2.5993392  1.9729633  2.4935768  2.9152358  2.0038307 ]\n",
      " [2.7740788  2.3112636  1.8753829  2.2255507  2.8877602  2.091115  ]\n",
      " [2.649899   2.4010527  2.3154407  1.9133563  2.931807   2.6959043 ]\n",
      " [2.9243994  2.758579   2.2590919  2.4318042  3.0011165  2.6122718 ]\n",
      " [2.3246467  1.9686329  1.8626267  2.1337276  2.1677196  1.5404842 ]\n",
      " [2.5351646  2.5282674  2.2898414  2.1645687  2.671163   1.6784582 ]\n",
      " [2.8547633  2.3726263  2.1192923  2.5018792  2.974576   2.0758703 ]\n",
      " [2.4930806  3.1719112  2.3553686  2.503947   2.8037598  2.582179  ]\n",
      " [2.661559   1.6886903  1.6555743  2.5814664  2.258018   1.5239782 ]\n",
      " [2.180039   2.0655167  1.7265528  1.9136591  2.0884042  1.3472378 ]\n",
      " [3.0500436  2.8989315  2.1021488  2.6150637  3.0321665  3.0032272 ]\n",
      " [3.06957    2.596085   2.158736   2.2953863  2.895739   2.3691478 ]\n",
      " [2.46711    2.3600497  2.2661052  2.3167381  2.4582634  2.440175  ]\n",
      " [2.44755    2.0519726  1.6330372  1.77903    2.1735685  1.7413844 ]\n",
      " [3.1415188  2.8706918  2.6411808  2.2549028  2.9297376  2.3867486 ]\n",
      " [2.607884   1.5156294  2.1968486  2.4111786  2.6360056  0.45856315]\n",
      " [2.8431299  1.6012853  1.6656456  1.9508994  2.5514655  0.67790335]\n",
      " [3.551017   2.630173   2.3189416  3.16989    2.9409325  2.9980202 ]\n",
      " [1.9054143  0.         0.2273053  0.4626611  2.1479402  0.        ]\n",
      " [2.6006603  2.474832   2.7161984  2.1829035  2.424046   3.2002792 ]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.020748   2.3430295  2.0022037  2.281384   2.7992141  2.288464  ]\n",
      " [3.170909   2.6971173  2.5528998  2.5351737  3.2946908  2.733784  ]\n",
      " [3.2826545  2.786646   2.552532   2.540015   3.091989   2.7694063 ]\n",
      " [3.3677876  3.1025934  2.5662298  2.5187235  3.3465874  2.8773985 ]\n",
      " [3.2793202  3.1854482  2.8681805  2.3576348  3.0458646  2.8690612 ]\n",
      " [3.035129   2.6532176  2.183807   2.2864797  2.8783388  2.6504147 ]\n",
      " [3.1677961  2.838779   2.5312662  2.519331   3.1588945  2.7816577 ]\n",
      " [2.6184595  2.4574919  2.3398867  2.3162394  2.9571733  2.4888282 ]\n",
      " [3.5662854  3.5372586  3.198513   3.1935315  3.5520816  3.7647877 ]\n",
      " [2.9304218  2.5531774  2.339741   2.3925865  2.91285    2.3731434 ]\n",
      " [3.0422301  2.5292215  2.4076006  2.4513383  2.8878796  2.3430414 ]\n",
      " [3.0588567  3.029148   2.6258943  2.1072443  2.8703043  2.5167894 ]\n",
      " [2.307891   2.3302648  1.9925182  2.0181236  2.4763372  1.6401193 ]\n",
      " [2.4852972  1.049302   1.5352522  2.5243793  2.3990016  0.871321  ]\n",
      " [2.2502615  0.42224035 1.446176   1.6660831  2.2975743  0.94815373]\n",
      " [3.2416801  2.6858206  2.736421   2.9234638  3.486486   3.0184174 ]\n",
      " [3.60709    3.0974035  3.2219954  2.9259326  3.5672574  2.6215851 ]\n",
      " [2.9159257  2.542399   2.1457865  2.61001    3.0412693  2.9366188 ]\n",
      " [2.8537407  2.5534275  2.2027688  2.411982   2.8524427  2.72215   ]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.6389666 2.9914021 2.6209803 2.6783876 3.3012486 2.9428687]\n",
      " [3.1835759 2.7458608 2.3850327 2.261425  2.944241  2.4110224]\n",
      " [2.8759732 2.5110335 2.6728034 2.6155543 3.182794  2.559538 ]\n",
      " [3.987403  3.3730114 3.3351681 3.1149526 3.8325095 3.4183288]\n",
      " [3.4621155 2.9425893 2.6433408 2.6496232 3.2107332 2.926772 ]\n",
      " [3.3399887 2.7997065 2.6040518 2.743925  3.1819758 2.7005057]\n",
      " [3.7898355 3.1298585 3.5076067 3.3472486 3.363291  3.6858225]\n",
      " [3.8276386 3.4485266 3.3463674 3.1322818 3.9128973 3.6404898]\n",
      " [3.6893778 3.37498   3.3970647 3.2065394 3.6427    3.168105 ]\n",
      " [3.3868756 2.665176  2.7733846 2.5283241 3.1334147 2.6350446]\n",
      " [3.930899  3.3129287 2.956173  2.9080958 3.5940301 3.276553 ]\n",
      " [3.7305233 2.9085531 2.5373158 2.7159824 3.2542956 2.8218234]\n",
      " [3.5390563 3.2057996 3.1342578 2.7734005 3.562187  2.9568143]\n",
      " [3.856313  3.1297045 3.0697484 2.897352  3.691262  3.52846  ]\n",
      " [3.6149607 3.6200488 3.7526665 2.9175365 3.7397833 3.144384 ]\n",
      " [3.5434797 3.1291647 3.2328749 3.1901062 3.5617888 3.603736 ]\n",
      " [3.1450028 2.810601  2.7928698 2.6676452 3.0180855 2.811349 ]\n",
      " [2.492534  2.4257479 1.8530166 2.1655388 2.74744   2.1078112]\n",
      " [3.5896003 3.2734847 2.9617877 2.7149763 3.5923972 3.0578809]\n",
      " [3.2992535 2.7060933 2.4620175 2.4396286 3.1216967 2.5756226]\n",
      " [3.6088693 2.9152732 2.7115602 2.6931882 3.2843766 2.8089924]\n",
      " [3.4758804 3.079195  3.0416749 2.8027284 3.2174854 2.7488441]\n",
      " [4.026716  3.3148336 3.184659  3.20104   3.7687287 3.530602 ]\n",
      " [3.9495912 4.531405  4.449063  3.3930707 4.045117  3.8042781]\n",
      " [3.4313173 3.0768843 3.085373  2.697848  3.1571498 2.9552164]\n",
      " [3.1758027 2.8729105 2.7146482 2.66951   3.0583143 2.8003936]\n",
      " [3.5000741 2.9213195 2.7022715 2.6013255 3.236357  2.937064 ]\n",
      " [3.5748448 3.451946  3.2448077 2.854265  3.6552958 3.1639054]\n",
      " [3.6853027 3.169804  3.0430336 2.944755  3.5909512 3.473577 ]\n",
      " [3.2855988 2.8024774 2.7270885 2.7687263 3.4449058 2.921033 ]\n",
      " [3.7736182 3.235591  2.880587  2.9084826 3.425364  2.9865992]\n",
      " [3.332871  2.78268   2.9055932 2.6976209 3.3540237 2.7941716]\n",
      " [4.302092  3.6310384 3.408709  3.4468462 4.049359  3.7293746]\n",
      " [2.9534686 2.5751905 2.2009518 2.5955958 2.8655267 2.5256884]\n",
      " [3.6507244 3.0410213 2.9501333 2.8254294 3.5126636 2.8583364]\n",
      " [3.4449456 2.9465141 2.6711397 2.546878  3.1855206 2.8376489]\n",
      " [4.053751  3.4538898 3.2729454 3.280776  4.0726967 3.7747812]\n",
      " [4.000267  3.388815  3.3979928 3.1211824 3.9137821 3.5220556]\n",
      " [3.8404014 3.2745771 2.924244  3.1602786 3.6040325 3.311892 ]\n",
      " [3.8232913 3.111074  3.0707889 2.841578  3.7457242 3.4210656]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.6894221 3.098926  2.9744065 2.9631667 3.525984  2.9589307]\n",
      " [3.7720277 3.364771  3.2120183 3.2431827 3.932017  3.4233527]\n",
      " [2.9592726 2.612052  2.8011646 2.5639815 3.4732952 2.852198 ]\n",
      " [3.1498373 2.5592399 2.3763366 2.5154276 3.135056  2.5896716]\n",
      " [3.3766432 2.694062  2.9465866 2.844224  3.4312642 3.38357  ]\n",
      " [3.1506684 2.9043102 2.4790409 2.5099185 3.0243835 2.50108  ]\n",
      " [3.4290254 2.6103246 2.9690802 2.8061671 3.465528  2.915647 ]\n",
      " [3.4384692 3.2212396 2.8713603 2.7683902 3.5414143 3.3425438]\n",
      " [3.817023  2.763909  3.194697  3.0313778 3.7226055 3.3781667]\n",
      " [3.4431515 3.0602713 2.7976215 2.557535  3.307521  2.9603624]\n",
      " [3.756649  2.9690595 2.840942  2.6757126 3.5563362 3.0305843]\n",
      " [3.3070827 3.0066466 2.7806067 2.110497  2.9851952 2.638112 ]\n",
      " [2.9089446 2.8503964 3.000701  3.0060544 3.1256702 1.5035306]\n",
      " [3.6618347 3.11229   3.6754727 2.7153409 3.2127433 3.901227 ]\n",
      " [3.5921082 2.6982923 2.7150564 2.8264422 3.5366578 3.4340012]\n",
      " [3.5986829 3.5406735 3.0751002 3.1216912 3.913002  3.8693855]\n",
      " [3.041549  2.4862287 3.0556896 2.386119  3.5087051 2.1532373]\n",
      " [3.243577  3.058685  2.9295492 2.800593  3.2612233 2.9296155]\n",
      " [4.136409  4.0849423 3.8581986 3.4838498 4.526821  3.8505957]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.7578225 2.9273057 2.7438087 2.7530365 3.4647737 3.2169044]\n",
      " [4.0979986 3.3738291 3.5687156 3.147368  4.0082517 3.7744064]\n",
      " [3.784101  2.9563193 2.7992055 2.9114797 3.5741112 3.2480235]\n",
      " [3.7768195 2.9669542 3.0093493 2.8397965 3.6418045 3.2222395]\n",
      " [4.1483088 3.5111892 3.4862952 3.3800492 4.0437703 3.4609869]\n",
      " [3.6466467 2.716496  2.9309282 3.088067  4.077378  2.3568628]\n",
      " [3.4610825 3.2239628 3.185873  2.594541  3.577094  2.954112 ]\n",
      " [3.9004507 3.2265303 2.4211023 2.3353798 3.7417243 2.8683753]\n",
      " [4.1185374 3.6361403 3.570692  3.2372494 3.9871075 3.3395824]\n",
      " [3.4969819 2.8436935 2.901926  3.0644293 3.7479389 3.6117592]\n",
      " [3.3841708 3.0288231 2.3799853 2.662299  3.3774524 2.6459553]\n",
      " [3.5075653 3.3530931 3.2433221 2.7918408 3.791385  3.3786936]\n",
      " [3.9557078 3.4850883 3.1922455 2.7419212 3.979348  3.2567272]\n",
      " [3.1413746 2.699359  2.436683  2.513826  3.12875   2.5024037]\n",
      " [3.1433182 2.8541448 2.587416  2.6417267 3.0385828 2.1270554]\n",
      " [4.0027375 3.4007459 3.2488728 2.8133354 3.7707357 2.953532 ]\n",
      " [2.8759253 2.493825  2.1479974 2.201789  3.0706115 2.4680095]\n",
      " [3.2817578 2.936923  2.4812326 2.0104167 3.1673532 2.5360165]\n",
      " [3.6478329 3.1002374 2.9247751 2.6996045 3.616437  2.9515564]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.6991107 3.0287762 2.8414252 2.854903  3.5875964 3.2182298]\n",
      " [3.7210822 3.2349806 3.1974494 3.090912  3.851093  3.2669377]\n",
      " [3.5137362 3.093007  3.1686306 3.2526457 3.8502913 3.1145036]\n",
      " [3.4186661 2.8312705 2.707685  2.446499  3.288319  2.6983669]\n",
      " [3.8482783 3.2085495 2.7073073 2.3475776 3.395453  2.6751983]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.6841202 3.3832927 2.989566  2.5821857 3.3243566 2.9654336]\n",
      " [2.9227853 2.788459  2.5061572 2.4873955 3.1957536 2.6350565]\n",
      " [2.723455  2.2972956 2.1001232 2.2677298 2.7470624 2.446584 ]\n",
      " [3.1117918 2.6358867 2.355025  2.427634  3.0053284 2.939938 ]\n",
      " [2.8241343 2.4180171 2.0079324 2.3038137 2.7756543 2.4105384]\n",
      " [3.5415692 3.191114  2.835278  2.6015687 3.3531327 3.0319383]\n",
      " [3.4840655 2.8753772 2.736187  2.6257467 3.1651306 2.630211 ]\n",
      " [3.4294777 3.173942  3.0323071 2.8716688 3.4868    3.104645 ]\n",
      " [3.3698916 3.7127976 2.6363816 2.4903297 3.3949733 3.4488633]\n",
      " [3.1788616 3.1850097 2.3596075 2.359673  3.4014142 2.847226 ]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.1047618 2.6913393 2.4579418 2.3783412 3.2407908 2.6268868]\n",
      " [3.7542524 3.1729908 2.9569173 2.7605348 3.4703474 3.0008178]\n",
      " [3.471124  2.7909641 2.6251397 2.4262066 3.321838  2.54133  ]\n",
      " [3.2904086 2.7304854 2.2930675 2.3363616 3.057761  2.4732654]\n",
      " [3.3500562 3.0799227 2.7532113 2.6650481 3.3229084 2.947593 ]\n",
      " [3.3443327 2.7017486 2.5945997 2.7484608 3.250821  2.9608436]\n",
      " [3.4657252 3.0017936 2.6143603 2.773032  3.3569698 2.6750822]\n",
      " [2.9614038 2.6984959 2.1679702 2.2488072 3.1375263 2.5576684]\n",
      " [3.2209709 2.9329145 2.6223016 2.7628148 3.531823  3.0174646]\n",
      " [4.315749  3.3107095 3.1262386 2.9527478 3.9342265 3.0227683]\n",
      " [3.8961568 3.5182333 3.262054  2.9305744 3.9743252 4.1285977]\n",
      " [2.8907757 2.740646  1.8764784 2.0077987 3.377731  1.875391 ]\n",
      " [3.0528402 2.7729833 2.323201  2.4918292 3.0946183 2.812769 ]\n",
      " [3.2366161 2.8049426 2.75871   2.1887064 3.2281117 2.4698713]\n",
      " [3.4557748 2.7991896 2.7059655 2.6999373 3.3840606 2.3645337]\n",
      " [3.8533354 3.6182947 3.0514548 3.216622  4.144931  2.693684 ]\n",
      " [3.47408   3.3631415 2.8568628 2.9468708 3.5337436 3.6335454]\n",
      " [3.3172803 3.2826922 2.885233  3.1735492 3.7271597 3.43015  ]\n",
      " [2.7210455 3.2515252 2.2965047 2.4605415 3.3581102 3.5570164]\n",
      " [3.76634   2.9928753 2.827772  3.0363255 3.6650348 3.12819  ]\n",
      " [3.9127853 3.8581066 3.5736022 3.0573251 3.9890525 3.8012073]\n",
      " [4.029199  4.755523  4.061505  3.3543591 4.513703  3.9197607]\n",
      " [3.9475079 3.295228  3.2868214 3.2519336 3.9836633 3.860283 ]\n",
      " [2.7779415 3.1891108 2.9173744 2.5520205 3.0942612 3.1169982]\n",
      " [3.644454  3.4098816 2.888477  2.4827785 3.3742943 3.1397915]\n",
      " [4.0841208 3.274858  3.2735612 3.1270509 4.016119  3.5804513]\n",
      " [3.5467076 2.9537435 3.1827724 2.599855  3.8111157 2.5442433]\n",
      " [3.5077934 3.4289403 3.087672  3.1242845 3.9023309 3.1525633]\n",
      " [3.2575607 2.838225  2.8887243 2.7061903 3.4759486 2.7139928]\n",
      " [3.0671654 2.9539676 2.3149707 2.3319454 3.1926947 2.5642023]\n",
      " [2.8932076 2.3605676 2.2560058 2.319929  2.9618425 2.7144647]\n",
      " [3.9723682 3.1332846 3.1485984 3.0445454 3.9207864 2.966155 ]\n",
      " [3.7137299 3.576074  2.6944745 2.2967265 3.698304  3.2225423]\n",
      " [3.7203617 2.9957929 2.7876306 2.6518993 3.2138262 2.9193842]\n",
      " [3.422693  2.9383194 2.6770668 2.7012014 3.2128258 2.7009141]\n",
      " [3.8609734 4.1437693 4.1960607 3.0500703 4.0281744 3.6162019]\n",
      " [3.3048882 3.978848  2.4993763 2.2877488 3.4538693 2.6546974]\n",
      " [3.839239  4.8269076 3.891285  4.097167  4.2604976 3.8769271]\n",
      " [3.11371   2.7333283 2.503662  2.341194  2.8723936 2.7772212]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.514471  2.7808814 2.5308747 1.957333  3.393153  2.4639654]\n",
      " [3.500195  3.1096327 3.1032119 2.8628147 3.5500703 3.0471776]\n",
      " [3.6055021 3.220589  2.930346  2.5777693 3.5755138 3.1685674]\n",
      " [3.8762183 3.3667433 3.1046848 2.9066253 3.6080112 3.5914633]\n",
      " [3.520607  2.9057646 2.735787  2.7035866 3.3024979 2.929529 ]\n",
      " [3.7713957 3.0864182 3.2383223 3.2737076 3.8074317 3.304962 ]\n",
      " [3.8517594 3.4834905 3.8483577 3.6824    4.115881  3.7730062]\n",
      " [3.718521  3.017669  2.8431773 2.787615  3.3198926 2.9902482]\n",
      " [4.0588293 3.7144685 3.8930118 3.422058  4.149746  4.1427927]\n",
      " [4.0360236 3.3433008 3.293038  3.0496283 3.908349  3.3983698]\n",
      " [3.6314783 3.2838762 3.0430503 2.760336  3.399877  2.9602451]\n",
      " [3.6028237 3.0482852 3.1949177 2.8539352 3.7231088 2.8215468]\n",
      " [2.9588342 2.9522097 2.3356102 2.2211149 2.976634  2.2233737]\n",
      " [3.2254627 2.5636907 2.4283142 2.1002026 2.861752  2.3412433]\n",
      " [3.2050138 2.781598  2.6329808 2.549057  3.0702457 2.4613302]\n",
      " [3.9160242 3.5119727 3.4414444 3.1618695 3.917008  3.3622074]\n",
      " [3.6511576 3.0243037 3.07262   2.9546008 3.5039558 3.1018238]\n",
      " [3.8995419 3.1937087 3.2224047 2.9373817 3.7889218 3.3475816]\n",
      " [3.4511166 2.9190974 2.7731788 2.6509094 3.3404741 2.7118483]\n",
      " [3.4408128 2.8675497 2.9546416 2.6637566 3.5319657 2.8091726]\n",
      " [3.7804508 3.1790447 3.088213  2.8794556 3.5067563 3.1546495]\n",
      " [3.911371  3.3610768 3.0229063 3.0811632 3.4982605 2.9937358]\n",
      " [3.6424608 3.3289905 2.9909606 2.936265  3.387915  3.1642895]\n",
      " [3.174721  2.6963024 2.5011954 2.5875533 3.0053353 2.728536 ]\n",
      " [3.299796  3.0060525 3.0077517 2.811379  3.4874961 3.421793 ]\n",
      " [3.6562834 2.8661222 2.7120707 2.6205683 3.1679642 2.7174716]\n",
      " [3.1118715 3.5348296 3.0803638 3.1944618 3.2550483 3.5008316]\n",
      " [3.3131819 2.9562163 2.6610737 2.5941346 3.3408146 2.8650892]\n",
      " [3.615498  3.1418462 2.7214522 2.7279782 3.2714868 2.6959074]\n",
      " [3.5093164 3.006717  2.9965672 2.6777525 3.272025  2.7689466]\n",
      " [3.811212  2.9184961 2.7718716 2.7952266 3.390314  2.9463794]\n",
      " [3.4337597 3.0960906 2.974222  2.925715  3.4869666 2.7639544]\n",
      " [3.764965  3.1026654 3.1124845 2.4824867 3.3089302 2.9457536]\n",
      " [3.8089955 2.8322697 2.609995  2.741644  3.304111  2.6601691]\n",
      " [3.5723653 3.0023062 2.7323751 2.7992723 3.4562378 2.9825091]\n",
      " [3.3711555 3.0532656 2.6687593 2.8865414 3.4543834 3.3206737]\n",
      " [3.6956053 3.1042528 2.8844774 2.902292  3.609656  3.5219426]\n",
      " [3.4757352 3.1959033 3.2091303 3.0780764 3.5474443 3.7119403]\n",
      " [3.731956  3.1046903 2.7468204 2.681539  3.4205687 2.8775496]\n",
      " [3.3358743 2.6888814 2.519841  2.3890436 3.1609387 2.6149678]\n",
      " [3.8543139 3.0755014 2.9553556 2.715489  3.6868267 3.1389737]\n",
      " [3.5727227 2.8967433 2.6829398 2.6237092 3.2375393 2.8179553]\n",
      " [3.4014602 3.062728  2.8855577 2.7658753 3.2641716 2.705181 ]\n",
      " [3.7594259 3.473001  3.3748853 3.047949  3.832766  3.2862308]\n",
      " [4.0881743 3.2580338 3.0024061 3.0549545 3.6824617 3.6647692]\n",
      " [4.196405  4.1893525 4.05981   3.5385613 4.1224394 3.5323143]\n",
      " [3.9627485 3.4752483 3.3276987 3.267994  3.702417  3.2407615]\n",
      " [3.8622568 3.4412587 3.5194886 3.0673027 3.7424536 3.4280887]\n",
      " [4.006727  3.1819355 3.0589688 2.9456825 3.8075323 3.6436465]\n",
      " [3.9487085 3.36609   3.1712186 3.1759758 4.04908   3.874664 ]\n",
      " [4.006745  3.2462282 3.311277  2.9719539 3.966487  3.7330685]\n",
      " [3.446064  2.9182994 2.5998518 2.624842  3.4578488 2.8979473]\n",
      " [3.6467166 3.0459833 2.9935539 2.9688148 3.7549555 3.0564165]\n",
      " [2.625503  2.4112556 1.9899    2.358798  3.108657  2.505493 ]\n",
      " [3.8293028 3.8394928 2.4318163 2.314053  3.4660838 3.3988762]\n",
      " [3.8193483 3.4386845 3.2466593 3.3723652 3.8204217 3.5695827]\n",
      " [3.8475657 3.5225046 3.3582711 2.9569483 3.8511581 3.54526  ]\n",
      " [3.6258733 3.322631  2.8955219 2.836989  3.412709  3.3385446]\n",
      " [4.318027  3.704328  3.2317057 3.3389723 3.7242067 3.0276253]\n",
      " [3.975608  3.2204957 3.388083  2.9789243 3.8380682 3.5712042]\n",
      " [3.8900104 3.11897   2.8738132 3.100987  3.6691213 3.0549395]\n",
      " [3.608855  3.2652404 3.039707  2.718676  3.3286843 2.577728 ]\n",
      " [4.0128403 3.463018  3.3004725 2.8069234 3.7153773 3.2783728]\n",
      " [3.9637575 3.4395785 3.2076283 3.1285489 4.09335   3.870177 ]\n",
      " [3.59767   3.2919958 3.3329635 3.156071  3.6283693 3.2538798]\n",
      " [3.1369548 2.6679218 2.253082  2.4877095 3.229354  3.0151916]\n",
      " [3.3568623 3.5421605 2.2573578 2.5555015 3.1728375 3.0961423]\n",
      " [4.167339  3.2760353 3.169386  3.0722952 3.8846917 3.5573483]\n",
      " [3.8060772 2.8962035 2.8615677 2.825731  3.5410452 3.1076431]\n",
      " [3.8819518 3.2411802 3.1305556 3.051794  3.9352899 3.4958515]\n",
      " [3.9335446 3.337584  3.1191862 2.9891145 3.617764  3.4576905]\n",
      " [3.6151247 2.990212  2.8210762 2.7071476 3.4442914 2.9938912]\n",
      " [3.6017709 3.1083071 3.2674658 3.130011  3.74737   3.5793047]\n",
      " [3.7871366 3.396483  3.388358  2.891159  3.763278  3.590394 ]\n",
      " [3.0852513 2.5203185 2.037384  2.4379635 3.1001604 2.2433732]\n",
      " [4.041069  3.5264554 3.3239574 3.0929356 3.8089705 3.6846871]\n",
      " [4.0808268 3.5496001 3.4505506 3.1461656 4.106982  3.7517328]\n",
      " [3.7829185 3.3791442 3.3316236 3.0579252 3.813912  3.4082432]\n",
      " [4.105712  3.2566767 3.2693257 3.1184096 3.8661265 3.3545175]\n",
      " [3.7093985 3.146224  2.9786134 2.638559  3.6485517 2.7627099]\n",
      " [3.299972  2.7177072 2.3327854 2.2192047 2.9005978 2.3298576]\n",
      " [3.3949022 3.0429645 2.413282  2.858529  3.683658  3.530432 ]\n",
      " [3.8449728 2.886129  2.7317035 2.7588308 3.4081755 3.2206721]\n",
      " [3.8246858 3.0331137 2.9347613 2.9229074 3.678555  3.351169 ]\n",
      " [4.0552254 3.4425294 3.284111  3.1975913 3.8691556 3.4856362]\n",
      " [3.2225156 2.7756886 2.8350606 2.6148615 3.4237142 3.171499 ]\n",
      " [3.7510414 3.6627364 3.4894247 2.8522668 3.6305473 3.691866 ]\n",
      " [3.8867962 3.325617  3.2709239 3.1781607 3.7195845 2.9347405]\n",
      " [4.01504   3.3588724 3.3294363 3.1820655 3.8289013 3.1793058]\n",
      " [3.7478616 3.527103  3.4991918 2.9978042 3.721248  3.5167897]\n",
      " [3.4190178 2.9484243 3.0106952 2.9066932 3.47386   3.1683245]\n",
      " [3.81151   3.478404  3.3476324 2.961841  3.785435  3.2514076]\n",
      " [4.1225686 3.8006968 4.1398406 3.4918957 4.352305  3.979194 ]\n",
      " [3.9757106 3.8493335 2.5501986 1.6141523 3.889422  2.9687119]\n",
      " [3.7336807 3.3042579 3.2380269 3.1869626 3.8110015 3.7452016]\n",
      " [3.3453789 3.137042  2.7826934 2.0843437 3.2296622 2.9053416]\n",
      " [4.110552  3.7445188 3.6650581 3.3329654 3.9702888 3.4641957]\n",
      " [4.2479234 4.1683207 3.8950171 3.5282202 4.100803  3.8835683]\n",
      " [3.199656  2.291217  2.6169777 2.381497  3.2269435 3.0709205]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[4.059313  3.439186  3.461721  3.284809  3.8973622 3.4077744]\n",
      " [4.0883274 3.436174  3.3607345 2.928505  3.728895  3.257565 ]\n",
      " [3.6397073 3.2463753 3.31312   2.981     3.5097742 3.495039 ]\n",
      " [3.89713   3.1543245 3.1697302 2.9078813 3.4929397 2.9565454]\n",
      " [3.5528824 3.293339  2.985807  2.7228487 3.414106  2.8804703]\n",
      " [3.9292011 3.454196  3.4213374 3.151896  3.899706  3.562621 ]\n",
      " [3.4836936 3.1255662 2.9521303 2.9385078 3.3749795 3.060614 ]\n",
      " [3.875134  3.2068336 2.9375358 2.7681541 3.3651109 3.2752275]\n",
      " [3.4970474 2.788068  2.5967689 2.5417752 3.0095804 2.4827592]\n",
      " [3.5979934 3.207674  2.6611586 2.459374  3.0602062 2.9604993]\n",
      " [3.2403998 2.7796733 2.5559525 2.6287646 3.0367086 2.3650439]\n",
      " [3.617766  3.0200555 2.862631  2.662405  3.3176117 2.848454 ]\n",
      " [4.1187916 3.5169764 3.3095133 3.114522  3.8544993 3.6458337]\n",
      " [3.4717596 2.9641006 2.699659  2.6730714 3.3164997 2.8331041]\n",
      " [3.4534554 3.196042  2.9969926 2.5858166 3.367126  2.8752267]\n",
      " [3.315771  3.2206016 3.3225965 2.8525062 3.5339892 3.0438046]\n",
      " [3.539841  3.2144883 2.8441846 2.945398  3.3226128 3.117267 ]\n",
      " [3.4587178 3.014533  2.6984258 2.9147651 3.3302054 2.7829332]\n",
      " [3.6228678 3.3424253 3.190185  2.8914976 3.4954724 3.4457765]\n",
      " [3.6783462 3.1996    2.8553872 3.0109997 3.5042405 3.104564 ]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.5817335 3.321005  2.9545462 2.7160149 3.435484  3.2718704]\n",
      " [4.01957   3.3794994 3.074646  3.122849  3.8035417 3.4544687]\n",
      " [2.7185364 2.3295417 2.103053  2.3587644 2.7238474 2.2204466]\n",
      " [3.1295683 2.786293  2.3770607 2.6132917 3.0838604 2.757497 ]\n",
      " [3.9211226 3.210475  2.9710922 3.0093837 3.6015735 3.4727058]\n",
      " [3.4125671 3.090344  2.7800667 2.751307  3.442012  3.3329482]\n",
      " [3.5284507 3.000958  2.9787266 2.928142  3.5258338 3.1454082]\n",
      " [3.1094847 2.6632547 2.6483343 2.4733672 2.9725542 2.7795954]\n",
      " [3.5844352 3.8189793 3.2824306 3.4242413 3.190049  2.9407322]\n",
      " [3.6434433 3.2718458 2.7147002 2.7093701 3.438202  2.618883 ]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.4706411 3.277377  2.7583137 2.9711514 3.3823628 2.8581996]\n",
      " [3.8105714 3.4672465 3.0122187 3.136028  3.6570108 3.507991 ]\n",
      " [3.5085073 2.9166198 2.5895815 2.8264098 3.3308423 2.8209362]\n",
      " [3.5095243 3.1292138 3.0471828 2.8609347 3.5146813 3.1541634]\n",
      " [3.7052062 3.098582  3.1327505 2.9036684 3.5180914 3.095988 ]\n",
      " [3.5563025 3.1842887 3.221369  3.0943787 3.7648125 3.3990276]\n",
      " [3.4687402 3.5617971 2.8741207 2.7997923 3.5134375 3.3236165]\n",
      " [3.3527422 2.8198032 2.6376963 2.3862104 3.4320471 2.9172153]\n",
      " [3.6277704 2.822933  2.7708726 2.5064683 3.4012082 2.831037 ]\n",
      " [3.6900063 2.9053874 2.8050554 2.61914   3.3944845 3.1535597]\n",
      " [3.277416  2.8344817 2.621408  2.7964802 3.2478852 3.0677736]\n",
      " [3.5920386 3.2462347 3.4022558 3.1987822 3.525163  3.3852162]\n",
      " [3.724407  2.943474  2.9718838 2.889109  3.5719461 3.2308266]\n",
      " [3.410492  3.214941  2.8772092 2.4726548 3.2855532 2.832681 ]\n",
      " [3.858932  3.576085  4.0982924 3.5914195 4.2315564 4.006601 ]\n",
      " [3.859513  3.2073808 3.0367908 2.9405391 3.5555701 3.416313 ]\n",
      " [3.8845565 3.247426  3.2756433 3.0019548 3.752744  3.580068 ]\n",
      " [3.7282896 3.022564  2.8695216 2.8310573 3.6090782 3.4227922]\n",
      " [3.9906993 3.308106  3.0928695 3.0124168 3.6994085 3.3770604]\n",
      " [3.4417062 2.966671  2.9189644 2.8969073 3.46807   3.2019448]\n",
      " [3.3767657 2.7730775 2.298616  2.6059065 3.0978208 2.6381695]\n",
      " [2.8993044 2.7963119 1.8992105 2.1875455 3.183989  2.5531168]\n",
      " [3.537507  2.8604407 2.4901924 2.474349  3.358471  2.9772794]\n",
      " [3.6030774 3.3505414 3.3547785 3.0574896 3.7873178 3.3170953]\n",
      " [4.0479584 2.9362936 3.2104099 3.3107142 3.8892972 3.4222867]\n",
      " [3.5204854 3.1019778 3.047472  3.0958986 3.8351521 3.538578 ]\n",
      " [3.8810577 3.0477085 2.918548  2.9414077 3.624     3.0935786]\n",
      " [4.121684  3.2504046 3.3522248 3.0446405 3.887025  3.5774155]\n",
      " [3.5424554 3.378541  3.034484  2.8996472 3.6328382 2.930499 ]\n",
      " [4.137081  3.4135628 3.4073114 3.2333975 3.8599062 2.9087532]\n",
      " [3.563552  3.10636   2.9093015 2.5694265 3.3878684 3.2541606]\n",
      " [4.2002244 3.5333328 3.3186812 3.1431203 4.2607417 3.7867534]\n",
      " [3.532896  3.3322227 3.0467222 3.276155  3.8581605 3.1531281]\n",
      " [2.9265099 2.5026634 2.3038073 2.277877  2.7311454 3.03011  ]\n",
      " [3.942227  3.0016816 2.863618  2.700315  3.754947  2.9776926]\n",
      " [3.8143973 3.0749602 2.8898954 2.7895565 3.6493235 3.3755593]\n",
      " [3.6164987 2.9980187 2.6761029 2.6087446 3.2570026 2.8340864]\n",
      " [3.785021  3.2358212 2.9968429 2.7303514 3.3597374 2.9622931]\n",
      " [3.4175186 2.9162626 2.5242984 2.6423717 3.1353056 3.0231142]\n",
      " [4.0963097 3.3267493 3.2049747 3.112241  3.608155  3.4360263]]\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "[[3.549693  3.1448798 2.8755    2.6946588 3.5024962 3.1611872]\n",
      " [3.81464   3.372127  3.0493534 2.9141808 3.5900354 3.4125023]\n",
      " [3.8840742 3.308537  2.9606285 3.0116725 3.7205768 3.5467803]\n",
      " [3.667626  2.935844  2.9913507 2.6055968 3.4486527 3.0201206]\n",
      " [3.6848662 3.243489  2.922153  2.7449899 3.5894122 3.3525908]]\n",
      "In fold 2\n",
      "\n",
      "load feature from files, there are 69 videos\n",
      "after deop:  69\n",
      "load feature from files, there are 14 videos\n",
      "after deop:  14\n",
      "(2229, 30, 28)\n",
      "(2229, 6)\n",
      "(473, 30, 28)\n",
      "(473, 6)\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.92636, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.92636 to 1.66003, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.66003 to 1.50453, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.50453 to 1.35465, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.35465 to 1.22588, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.22588 to 1.03740, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03740 to 0.96893, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.96893 to 0.88880, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.88880 to 0.73505, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.73505 to 0.62097, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.62097 to 0.61385, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.61385 to 0.57522, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.57522 to 0.51292, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51292 to 0.47891, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47891\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.47891 to 0.40140, saving model to model_zoo/MTmodel.h5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.40140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b3c0a98a61a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m                        \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_of_testdata\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m      )\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1008 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_gear_score_folds=[]\n",
    "it=1\n",
    "for train_video_number,test_video_number in zip(train_fold,test_fold):\n",
    "    print(\"In fold %d\\n\" %it)\n",
    "    it+=1\n",
    "    # -----------in each fold ---------------------------------------------------\n",
    "    # train test split by people\n",
    "    train_video,train_video_label=fh.make_train_test_data_from_video_numbers(folder,train_video_number,video_clips_length,time_lag,move_threshold,stride,ll)\n",
    "    test_video,test_video_label=fh.make_train_test_data_from_video_numbers(folder,test_video_number,video_clips_length,time_lag,move_threshold,stride,ll)\n",
    "    print(train_video.shape)\n",
    "    print(train_video_label.shape)\n",
    "    print(test_video.shape)\n",
    "    print(test_video_label.shape)\n",
    "    \n",
    "    # -----------pre-processing  ---------------------------------------------------\n",
    "    X_train=train_video/640-0.5\n",
    "    X_test=test_video/640-0.5\n",
    "    y_train=train_video_label/5\n",
    "    y_test=test_video_label/5\n",
    "\n",
    "    # -----------init data generator  ---------------------------------------------------\n",
    "    sample_of_trainningdata=X_train.shape[0]\n",
    "    sample_of_testdata=X_test.shape[0]\n",
    "    batch_size=64\n",
    "    train_gen=generator(X_train, y_train, batch_size,0.1)\n",
    "    val_gen=generator(X_test, y_test, batch_size,0)\n",
    "\n",
    "    # -----------#prepare for model in&out shape ---------------------------------------------------\n",
    "    clip_lenth=X_train.shape[1]\n",
    "    dimension=X_train.shape[2]\n",
    "    l2_lambda=0.01\n",
    "    model=make_model(0.01,clip_lenth,dimension)\n",
    "\n",
    "    callbacks_list = get_callback_list_by_model('MTmodel')\n",
    "    \n",
    "    model_h=model.fit_generator(train_gen,\n",
    "                        steps_per_epoch=sample_of_trainningdata//batch_size,\n",
    "                        epochs=20,\n",
    "                        validation_data=val_gen,\n",
    "                       validation_steps=sample_of_testdata//batch_size,\n",
    "                        verbose=0,\n",
    "                        callbacks=callbacks_list\n",
    "     )\n",
    "    \n",
    "    # -----------#plot training results ---------------------------------------------------\n",
    "    ax=plt.figure(figsize=(12,14))\n",
    "    ax = plt.subplot(421)\n",
    "    ax.plot(model_h.history['loss'])\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.xlabel('epochs')\n",
    "\n",
    "    ax = plt.subplot(422)\n",
    "    ax.plot(model_h.history['val_loss'])\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    model.load_weights('model_zoo/MTmodel.h5')\n",
    "    \n",
    "    # -----------calcuate pre gear score acc ---------------------------------------------------\n",
    "    valid_arr=np.zeros(6)\n",
    "    for t_number in test_video_number:\n",
    "        re,gt = model_predit_by_videoNumber(model,folder,t_number,video_clips_length,time_lag,move_threshold,stride,ll) \n",
    "        print(re)\n",
    "        re=np.round(np.median(re,axis=0))\n",
    "        score_range=ll.get_video_score_range_by_video_number(t_number)\n",
    "        maxScore=score_range[0]\n",
    "        minScore=score_range[1]\n",
    "        for index,val in enumerate(['DP','BD','E','FS','A','RC']):\n",
    "            if re[index]>=int(minScore[val]) and re[index]<=int(maxScore[val]):\n",
    "                valid_arr[index]+=1\n",
    "    per_gear_score_folds.append(valid_arr/len(test_video_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6875, 0.75  , 0.5625, 0.625 , 0.625 , 0.625 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 1\n",
      "Predict Score vs GT Score: 2.097516 18.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 2\n",
      "Predict Score vs GT Score: 2.053531 26.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 0\n",
      "Predict Score vs GT Score: 1.9037879 11.0\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 1\n",
      "Predict Score vs GT Score: 2.0681698 19.0\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 0\n",
      "Predict Score vs GT Score: 1.9576005 10.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 1\n",
      "Predict Score vs GT Score: 1.8438017 14.0\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 0\n",
      "Predict Score vs GT Score: 1.8453907 7.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 1\n",
      "Predict Score vs GT Score: 2.0444 21.0\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 0\n",
      "Predict Score vs GT Score: 1.9443357 11.0\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 0\n",
      "Predict Score vs GT Score: 1.7576591 9.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 2\n",
      "Predict Score vs GT Score: 2.0378907 27.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 2\n",
      "Predict Score vs GT Score: 1.9674852 24.0\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 2\n",
      "Predict Score vs GT Score: 1.8588974 21.5\n",
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n",
      "Predict vs GT level: 0 2\n",
      "Predict Score vs GT Score: 1.859124 23.0\n"
     ]
    }
   ],
   "source": [
    "predict_label=[]\n",
    "gt_label=[]\n",
    "for t_number in test_video_number:\n",
    "#     print(\"Video:\",t_number)\n",
    "    re,gt = model_predit_by_videoNumber(model,folder,t_number,video_clips_length,time_lag,move_threshold,stride,ll)  \n",
    "#     print('\\n')\n",
    "    \n",
    "    predict_level,predict_totalScore=convert_to_skill(re,'median')\n",
    "    \n",
    "    gt_level,gt_totalScore=ll.get_video_level_by_video_number(t_number,'median')\n",
    "    \n",
    "    print(\"Predict vs GT level:\",predict_level,gt_level)\n",
    "    print(\"Predict Score vs GT Score:\",predict_totalScore,gt_totalScore)\n",
    "    predict_label.append(predict_level)\n",
    "    gt_label.append(gt_level)\n",
    "\n",
    "    vmax,vmin=ll.get_video_score_range_by_video_number(t_number)\n",
    "#     plot(re,gt,vmax,vmin,detail=False)\n",
    "#     print(\"----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 2, 2, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(predict_label)==np.array(gt_label))/len(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
