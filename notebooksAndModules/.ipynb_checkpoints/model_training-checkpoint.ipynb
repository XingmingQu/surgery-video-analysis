{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import an awesome Label helper\n",
      "import an awesome feature helper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import modules.labelHelper as lh \n",
    "import modules.featureHelper as fh\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Conv1D, GlobalAveragePooling1D, MaxPooling1D,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,average, concatenate,RepeatVector,Lambda,add,subtract,Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Input, Model\n",
    "from sklearn import metrics as mt\n",
    "from skimage.io import imshow\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "warnings.filterwarnings('ignore')\n",
    "from modules.modelTools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 videos in total\n",
      "\n",
      "There are 19 trainees in total\n",
      "\n",
      " Number of Videos from each person\n",
      "Akhtar          -- [176 253 761] ----: 3\n",
      "Cadeddu         -- [164 171] ----: 2\n",
      "Crivelli        -- [225 276 333 425] ----: 4\n",
      "Gahan           -- [257 345 378 384 486] ----: 5\n",
      "Johnson         -- [441 615] ----: 2\n",
      "Keith           -- [240 277 717] ----: 3\n",
      "Kenigsberg      -- [ 78 440 455 471 881] ----: 5\n",
      "Krabbe          -- [152 344 527 861] ----: 4\n",
      "Marthur         -- [130 194 222 368 921] ----: 5\n",
      "Mollengarden    -- [ 59 143 267 460] ----: 4\n",
      "Moony           -- [294 301 361 498 539] ----: 5\n",
      "Passoni         -- [207 237 895 942] ----: 4\n",
      "Rozanski        -- [113 302 716] ----: 3\n",
      "Satyanarayan    -- [ 16  74 236 358 436 457 503 537 557 578 599 632 689] ----: 13\n",
      "Singla          -- [ 49 536 538] ----: 3\n",
      "Sorokin         -- [ 91 226 507 530] ----: 4\n",
      "Timburlake      -- [258 296 559 742] ----: 4\n",
      "Tse             -- [ 11 283 414 427 562 928] ----: 6\n",
      "Varun           -- [192 401 417 820] ----: 4\n",
      "train on videos from:\n",
      " ['Kenigsberg', 'Keith', 'Krabbe', 'Cadeddu', 'Johnson', 'Satyanarayan', 'Moony', 'Akhtar', 'Tse', 'Rozanski', 'Varun', 'Gahan', 'Marthur', 'Timburlake', 'Sorokin']\n",
      "test on videos from:\n",
      " ['Singla', 'Crivelli', 'Mollengarden', 'Passoni']\n",
      "[ 78 440 455 471 881 240 277 717 152 344 527 861 164 171 441 615  16  74\n",
      " 236 358 436 457 503 537 557 578 599 632 689 294 301 361 498 539 176 253\n",
      " 761  11 283 414 427 562 928 113 302 716 192 401 417 820 257 345 378 384\n",
      " 486 130 194 222 368 921 258 296 559 742  91 226 507 530]\n",
      "[ 49 536 538 225 276 333 425  59 143 267 460 207 237 895 942]\n",
      "load feature from files, there are 68 videos\n",
      "after deop:  68\n",
      "load feature from files, there are 15 videos\n",
      "after deop:  15\n",
      "(2320, 30, 28)\n",
      "(2320, 6)\n",
      "(382, 30, 28)\n",
      "(382, 6)\n"
     ]
    }
   ],
   "source": [
    "ll=lh.Label('..//2019_fall_labels.csv')\n",
    "print(\"There are %d videos in total\\n\"%ll.video_count())\n",
    "ll.get_trainee_info()\n",
    "\n",
    "train_video_number,test_video_number=ll.train_test_split_on_people(0.2)\n",
    "print(train_video_number)\n",
    "print(test_video_number)\n",
    "\n",
    "## set up feature parameters ##\n",
    "folder = \"C:\\\\2019_fall_video_features\"\n",
    "video_clips_length=30\n",
    "time_lag=2\n",
    "move_threshold=150\n",
    "stride=video_clips_length\n",
    "\n",
    "# train test split by people\n",
    "train_video,train_video_label=fh.make_train_test_data_from_video_numbers(folder,train_video_number,video_clips_length,time_lag,move_threshold,stride,ll)\n",
    "test_video,test_video_label=fh.make_train_test_data_from_video_numbers(folder,test_video_number,video_clips_length,time_lag,move_threshold,stride,ll)\n",
    "print(train_video.shape)\n",
    "print(train_video_label.shape)\n",
    "print(test_video.shape)\n",
    "print(test_video_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2320 samples, validate on 382 samples\n",
      "Epoch 1/30\n",
      "2320/2320 [==============================] - 9s 4ms/step - loss: 2.2203 - DP_loss: 0.4238 - BD_loss: 0.3415 - E_loss: 0.3661 - FS_loss: 0.3173 - A_loss: 0.3609 - RC_loss: 0.3649 - val_loss: 2.2266 - val_DP_loss: 0.5064 - val_BD_loss: 0.3843 - val_E_loss: 0.4165 - val_FS_loss: 0.2308 - val_A_loss: 0.3404 - val_RC_loss: 0.3023\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.22661, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 2/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 1.5152 - DP_loss: 0.2474 - BD_loss: 0.2574 - E_loss: 0.3097 - FS_loss: 0.2218 - A_loss: 0.2149 - RC_loss: 0.2179 - val_loss: 1.2602 - val_DP_loss: 0.1940 - val_BD_loss: 0.1737 - val_E_loss: 0.3758 - val_FS_loss: 0.1289 - val_A_loss: 0.1512 - val_RC_loss: 0.1906\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.22661 to 1.26017, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 3/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 1.0948 - DP_loss: 0.1550 - BD_loss: 0.1653 - E_loss: 0.2377 - FS_loss: 0.1493 - A_loss: 0.1675 - RC_loss: 0.1741 - val_loss: 0.5503 - val_DP_loss: 0.0663 - val_BD_loss: 0.0921 - val_E_loss: 0.1509 - val_FS_loss: 0.0387 - val_A_loss: 0.0687 - val_RC_loss: 0.0877\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.26017 to 0.55031, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 4/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.7982 - DP_loss: 0.1118 - BD_loss: 0.1082 - E_loss: 0.1585 - FS_loss: 0.1086 - A_loss: 0.1275 - RC_loss: 0.1378 - val_loss: 0.5278 - val_DP_loss: 0.0683 - val_BD_loss: 0.0933 - val_E_loss: 0.1121 - val_FS_loss: 0.0400 - val_A_loss: 0.0696 - val_RC_loss: 0.0986\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55031 to 0.52777, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 5/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.6624 - DP_loss: 0.0960 - BD_loss: 0.0849 - E_loss: 0.1313 - FS_loss: 0.0900 - A_loss: 0.1047 - RC_loss: 0.1098 - val_loss: 0.6505 - val_DP_loss: 0.0941 - val_BD_loss: 0.1085 - val_E_loss: 0.1440 - val_FS_loss: 0.0421 - val_A_loss: 0.1030 - val_RC_loss: 0.1133\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52777\n",
      "Epoch 6/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.5834 - DP_loss: 0.0875 - BD_loss: 0.0724 - E_loss: 0.1018 - FS_loss: 0.0791 - A_loss: 0.1000 - RC_loss: 0.0972 - val_loss: 0.4916 - val_DP_loss: 0.0650 - val_BD_loss: 0.0868 - val_E_loss: 0.1027 - val_FS_loss: 0.0326 - val_A_loss: 0.0710 - val_RC_loss: 0.0883\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52777 to 0.49165, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 7/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.5350 - DP_loss: 0.0749 - BD_loss: 0.0680 - E_loss: 0.0956 - FS_loss: 0.0741 - A_loss: 0.0854 - RC_loss: 0.0917 - val_loss: 0.4911 - val_DP_loss: 0.0615 - val_BD_loss: 0.0820 - val_E_loss: 0.1091 - val_FS_loss: 0.0336 - val_A_loss: 0.0716 - val_RC_loss: 0.0883\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49165 to 0.49108, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 8/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.5033 - DP_loss: 0.0734 - BD_loss: 0.0597 - E_loss: 0.0882 - FS_loss: 0.0714 - A_loss: 0.0835 - RC_loss: 0.0823 - val_loss: 0.5363 - val_DP_loss: 0.0744 - val_BD_loss: 0.0870 - val_E_loss: 0.1123 - val_FS_loss: 0.0388 - val_A_loss: 0.0806 - val_RC_loss: 0.0985\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.49108\n",
      "Epoch 9/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4914 - DP_loss: 0.0719 - BD_loss: 0.0576 - E_loss: 0.0837 - FS_loss: 0.0715 - A_loss: 0.0843 - RC_loss: 0.0781 - val_loss: 0.4372 - val_DP_loss: 0.0521 - val_BD_loss: 0.0777 - val_E_loss: 0.0922 - val_FS_loss: 0.0307 - val_A_loss: 0.0626 - val_RC_loss: 0.0777\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.49108 to 0.43721, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 10/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4723 - DP_loss: 0.0674 - BD_loss: 0.0535 - E_loss: 0.0809 - FS_loss: 0.0679 - A_loss: 0.0784 - RC_loss: 0.0802 - val_loss: 0.4785 - val_DP_loss: 0.0603 - val_BD_loss: 0.0820 - val_E_loss: 0.1067 - val_FS_loss: 0.0347 - val_A_loss: 0.0665 - val_RC_loss: 0.0847\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.43721\n",
      "Epoch 11/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4430 - DP_loss: 0.0627 - BD_loss: 0.0504 - E_loss: 0.0754 - FS_loss: 0.0634 - A_loss: 0.0748 - RC_loss: 0.0727 - val_loss: 0.6584 - val_DP_loss: 0.0951 - val_BD_loss: 0.0924 - val_E_loss: 0.1507 - val_FS_loss: 0.0520 - val_A_loss: 0.1039 - val_RC_loss: 0.1210\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.43721\n",
      "Epoch 12/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4356 - DP_loss: 0.0617 - BD_loss: 0.0479 - E_loss: 0.0730 - FS_loss: 0.0650 - A_loss: 0.0732 - RC_loss: 0.0718 - val_loss: 0.6266 - val_DP_loss: 0.0893 - val_BD_loss: 0.0889 - val_E_loss: 0.1334 - val_FS_loss: 0.0497 - val_A_loss: 0.1041 - val_RC_loss: 0.1184\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.43721\n",
      "Epoch 13/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4157 - DP_loss: 0.0576 - BD_loss: 0.0452 - E_loss: 0.0696 - FS_loss: 0.0617 - A_loss: 0.0706 - RC_loss: 0.0685 - val_loss: 0.4512 - val_DP_loss: 0.0554 - val_BD_loss: 0.0770 - val_E_loss: 0.0949 - val_FS_loss: 0.0345 - val_A_loss: 0.0670 - val_RC_loss: 0.0802\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.43721\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4113 - DP_loss: 0.0579 - BD_loss: 0.0442 - E_loss: 0.0697 - FS_loss: 0.0608 - A_loss: 0.0681 - RC_loss: 0.0686 - val_loss: 0.5734 - val_DP_loss: 0.0798 - val_BD_loss: 0.0863 - val_E_loss: 0.1222 - val_FS_loss: 0.0481 - val_A_loss: 0.0936 - val_RC_loss: 0.1015\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.43721\n",
      "Epoch 15/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.4062 - DP_loss: 0.0561 - BD_loss: 0.0438 - E_loss: 0.0704 - FS_loss: 0.0592 - A_loss: 0.0689 - RC_loss: 0.0660 - val_loss: 0.5523 - val_DP_loss: 0.0755 - val_BD_loss: 0.0840 - val_E_loss: 0.1219 - val_FS_loss: 0.0401 - val_A_loss: 0.0868 - val_RC_loss: 0.1025\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.43721\n",
      "Epoch 16/30\n",
      "2320/2320 [==============================] - 3s 1ms/step - loss: 0.3894 - DP_loss: 0.0535 - BD_loss: 0.0442 - E_loss: 0.0650 - FS_loss: 0.0573 - A_loss: 0.0655 - RC_loss: 0.0624 - val_loss: 0.6164 - val_DP_loss: 0.0800 - val_BD_loss: 0.0933 - val_E_loss: 0.1359 - val_FS_loss: 0.0588 - val_A_loss: 0.1004 - val_RC_loss: 0.1068\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.43721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c27a3cbfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=train_video/640-0.5\n",
    "X_test=test_video/640-0.5\n",
    "y_train=train_video_label/5\n",
    "y_test=test_video_label/5\n",
    "#     y_train=y_train\n",
    "#     y_test=y_test\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print(X_test.shape,y_test.shape)\n",
    "\n",
    "# DP = []  \n",
    "# BD = []\n",
    "# E = []\n",
    "# FS = []\n",
    "# A = []\n",
    "# RC = []\n",
    "# for i in range(len(y_test)):\n",
    "#     DP.append(y_test[i][0])\n",
    "#     BD.append(y_test[i][1])\n",
    "#     E.append(y_test[i][2])\n",
    "#     FS.append(y_test[i][3])\n",
    "#     A.append(y_test[i][4])\n",
    "#     RC.append(y_test[i][5])\n",
    "# y_test_labels = [np.array(DP),np.array(BD),np.array(E),np.array(FS), np.array(A),np.array(RC)]\n",
    "# DP = []  \n",
    "# BD = []\n",
    "# E = []\n",
    "# FS = []\n",
    "# A = []\n",
    "# RC = []\n",
    "# for i in range(len(y_train)):\n",
    "#     DP.append(y_train[i][0])\n",
    "#     BD.append(y_train[i][1])\n",
    "#     E.append(y_train[i][2])\n",
    "#     FS.append(y_train[i][3])\n",
    "#     A.append(y_train[i][4])\n",
    "#     RC.append(y_train[i][5])\n",
    "# y_trin_labels = [np.array(DP),np.array(BD),np.array(E),np.array(FS), np.array(A),np.array(RC)]\n",
    "sample_of_trainningdata=X_train.shape[0]\n",
    "sample_of_testdata=X_test.shape[0]\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_gen=generator(X_train, y_train, batch_size,0.1)\n",
    "val_gen=generator(X_test, y_test, batch_size,0)\n",
    "\n",
    "#prepare for inout shape\n",
    "clip_lenth=X_train.shape[1]\n",
    "dimension=X_train.shape[2]\n",
    "l2_lambda=0.01\n",
    "model=make_model(0.01,clip_lenth,dimension)\n",
    "callbacks_list = get_callback_list_by_model('MTmodel')\n",
    "# model_h=model.fit_generator(train_gen,\n",
    "#                     steps_per_epoch=sample_of_trainningdata//batch_size,\n",
    "#                     epochs=30,\n",
    "#                     validation_data=val_gen,\n",
    "#                    validation_steps=sample_of_testdata//batch_size,\n",
    "#                     verbose=1,\n",
    "#                     callbacks=callbacks_list\n",
    "#  )\n",
    "# model.fit(x=X_train, # create a list of inputs for embeddings\n",
    "#         y=y_trin_labels, epochs=30, \n",
    "#         batch_size=16, verbose=1,\n",
    "#         validation_data = (X_test,y_test_labels),\n",
    "#         callbacks=callbacks_list         \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_zoo/MTmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predit_by_videoNumber(model,folder,vNum,video_clips_length,time_lag,move_threshold,stride,label):\n",
    "    vNum=[vNum]\n",
    "    video,video_label = fh.make_train_test_data_from_video_numbers(folder,vNum,video_clips_length,time_lag,move_threshold,stride,label)\n",
    "    result = model.predict(video)\n",
    "    return result,video_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feature from files, there are 1 videos\n",
      "after deop:  1\n"
     ]
    }
   ],
   "source": [
    "re,gt =model_predit_by_videoNumber(model,folder,16,video_clips_length,time_lag,move_threshold,stride,ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 1574.6099],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [15929.724 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [15400.154 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 6888.237 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 4865.3955],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 1286.707 ],\n",
       "        [ 1259.3091],\n",
       "        [ 6177.1636],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 5215.007 ],\n",
       "        [    0.    ],\n",
       "        [ 9075.03  ],\n",
       "        [ 1736.5962],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 3419.9429],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ]], dtype=float32), array([[   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [ 438.76752 ],\n",
       "        [  39.300026],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [1116.4563  ],\n",
       "        [   0.      ],\n",
       "        [1657.788   ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ],\n",
       "        [   0.      ]], dtype=float32), array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32), array([[   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [2024.463],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ],\n",
       "        [   0.   ]], dtype=float32), array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32), array([[    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [22447.06  ],\n",
       "        [40051.06  ],\n",
       "        [33185.832 ],\n",
       "        [20789.82  ],\n",
       "        [42171.05  ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [16524.303 ],\n",
       "        [ 1495.8774],\n",
       "        [13359.761 ],\n",
       "        [18484.951 ],\n",
       "        [55458.645 ],\n",
       "        [23488.4   ],\n",
       "        [13369.473 ],\n",
       "        [12943.729 ],\n",
       "        [ 5967.6323],\n",
       "        [13786.889 ],\n",
       "        [13741.177 ],\n",
       "        [13235.802 ],\n",
       "        [    0.    ],\n",
       "        [24818.56  ],\n",
       "        [47841.254 ],\n",
       "        [ 8814.096 ],\n",
       "        [10273.281 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [18355.568 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [33442.16  ],\n",
       "        [    0.    ],\n",
       "        [ 1445.4751],\n",
       "        [12693.776 ],\n",
       "        [19885.428 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [52911.836 ],\n",
       "        [ 6582.388 ],\n",
       "        [    0.    ],\n",
       "        [ 4584.849 ],\n",
       "        [26737.23  ],\n",
       "        [30698.004 ],\n",
       "        [13227.032 ],\n",
       "        [13579.822 ],\n",
       "        [15030.187 ],\n",
       "        [ 4314.738 ],\n",
       "        [18554.838 ],\n",
       "        [36388.9   ],\n",
       "        [25097.664 ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [34550.05  ],\n",
       "        [49023.133 ],\n",
       "        [36718.742 ],\n",
       "        [ 5961.511 ],\n",
       "        [24200.998 ],\n",
       "        [    0.    ],\n",
       "        [17328.371 ],\n",
       "        [ 8287.956 ],\n",
       "        [37619.99  ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [    0.    ],\n",
       "        [ 5565.9683]], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
