{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.models import Sequential,Model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Activation, Input,RepeatVector,Embedding, Flatten, Concatenate,Dropout\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn import metrics as mt\n",
    "from keras import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import average, concatenate,RepeatVector,Lambda,add,subtract\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import random\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import pickle\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Reshape,Add\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D,AveragePooling1D\n",
    "from keras.regularizers import l2 \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroe(y_true,y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"ACC:\",accuracy_score(y_true, y_pred))\n",
    "\n",
    "#Prepare Data\n",
    "\n",
    "# with open('final_data_dude_rd2.npy', 'rb') as handle:\n",
    "data = np.load('final_data_dude_rd2_opp.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45609\n",
      "Class 1: 22805\n",
      "[[1184, '3E37'], [1156, '2QD9'], [1144, '830C'], [1084, '2RGP'], [1074, '3KL6'], [1072, '1XL2'], [1066, '2I78'], [1064, '2OI0'], [1048, '3EL8'], [1016, '3L3M'], [984, '1BCD'], [968, '2GTK'], [964, '3EML'], [960, '3PBL'], [948, '1H00'], [922, '1YPE'], [906, '1E66'], [898, '2AYW'], [870, '3LN1'], [840, '2OF2'], [818, '2P2I'], [796, '1UDT'], [766, '1SJ0'], [746, '2P54'], [734, '2FSZ'], [676, '3LAN'], [660, '3FRJ'], [586, '3KBA'], [586, '3CQW'], [566, '3L5D'], [564, '3BKL'], [538, '2AM9'], [515, '3BQD'], [494, '2VT4'], [480, '2ZNP'], [462, '3NY8'], [462, '3NXO'], [398, '2CNK'], [390, '2OYU'], [370, '3MAX'], [364, '2HZI'], [342, '3CHP'], [340, '3NXU'], [340, '3F07'], [340, '3CCW'], [332, '3LQ8'], [332, '3KRJ'], [332, '3G0E'], [324, '1SQT'], [318, '2HV5'], [316, '3KGC'], [304, '3D4Q'], [296, '2ZEC'], [296, '2OJ9'], [278, '3C4F'], [276, '2ICA'], [270, '2I0E'], [266, '3HMM'], [262, '1MV9'], [260, '2AZR'], [244, '1S3B'], [242, '3EQH'], [240, '1R9O'], [234, '3D0E'], [232, '3CJO'], [228, '1W7X'], [222, '1J4H'], [222, '1D3G'], [218, '1SYN'], [214, '3LPB'], [214, '2OWB'], [208, '3G6Z'], [208, '2ZDT'], [206, '3BGS'], [206, '1Q4X'], [204, '3BIZ'], [204, '1LRU'], [202, '3M2W'], [202, '1VSO'], [200, '3NF7'], [200, '3HL5'], [200, '3BZ3'], [200, '2ETR'], [200, '1QW6'], [198, '1KVO'], [196, '1B9V'], [188, '2AA2'], [186, '2E1W'], [184, '3F9M'], [176, '1UYG'], [170, '1ZW5'], [158, '2OJG'], [154, '1C8K'], [126, '1LI4'], [114, '2B8T'], [108, '2V3F'], [100, '1NJS'], [96, '1L2S'], [94, '2NNQ'], [86, '2H7L'], [82, '3BWM'], [80, '3ODU']]\n",
      "102\n",
      "72\n",
      "(45609, 2, 9000) (45609, 512) (45609,)\n",
      "Class 0: 22804\n",
      "ratio: 1.0000438519557973\n"
     ]
    }
   ],
   "source": [
    "X, proteins, ic50 = data['X'], data['proteins'], data['ic50']\n",
    "print(len(X))\n",
    "k = sum(ic50)\n",
    "\n",
    "print ('Class 1:',k)\n",
    "\n",
    "td = {}\n",
    "\n",
    "pr = data['pr_names']\n",
    "\n",
    "for i in pr:\n",
    "\tif i not in td:\n",
    "\t\ttd[i] = 1\n",
    "\telse:\n",
    "\t\ttd[i] += 1\n",
    "li = [[td[i], i] for i in td]\n",
    "li.sort(reverse = True)\n",
    "print (li)\n",
    "li = [i[1] for i in li]\n",
    "\n",
    "print (len(li))\n",
    "#train = li[:10] + list(random.choices(li[10:], k = 62))\n",
    "train = list(random.choices(li, k = 72))\n",
    "print (len(train))\n",
    "#test = list(set(np.unique(pr)) - set(train))\n",
    "fac = []\n",
    "fac_t = []\n",
    "for i in range (len(pr)):\n",
    "\tif pr[i] in train:\n",
    "\t\tfac.append(i)\n",
    "\telse:\n",
    "\t\tfac_t.append(i)\n",
    "fac = np.array(fac)\n",
    "fac_t = np.array(fac_t)\n",
    "\n",
    "proteins = np.array(proteins)\n",
    "X = np.array(X)\n",
    "ic50 = np.array(ic50)\n",
    "\n",
    "print (proteins.shape, X.shape, ic50.shape)\n",
    "print(\"Class 0:\",(len(ic50)-sum(ic50)) )\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "a, b = sum(ic50), len(ic50)-sum(ic50)\n",
    "print('ratio:',sum(ic50)/(len(ic50)-sum(ic50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9000)\n",
      "512\n",
      "(22921, 512) (22688, 512)\n"
     ]
    }
   ],
   "source": [
    "Proeins_shape=proteins.shape[1:]\n",
    "Drags_shape=X.shape[1]\n",
    "print(Proeins_shape)\n",
    "print(Drags_shape)\n",
    "\n",
    "train_X = X[fac]\n",
    "valid_X = X[fac_t]\n",
    "\n",
    "train_proteins = proteins[fac]\n",
    "valid_proteins = proteins[fac_t]\n",
    "\n",
    "train_y = ic50[fac]\n",
    "valid_y = ic50[fac_t]\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "print (train_X.shape, valid_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback_list_by_model(model_name):\n",
    " \n",
    "    checkpoint = ModelCheckpoint('model_zoo/'+model_name+'.h5', monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True, mode='min', save_weights_only = True)\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                       verbose=1, mode='auto', epsilon=0.0001)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", \n",
    "                          mode=\"min\", \n",
    "                          patience=7)\n",
    "    csv_logger = CSVLogger(filename='./training_log_'+model_name+'.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "    \n",
    "    callbacks_list = [checkpoint,reduceLROnPlat, early,csv_logger]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,model_name,Epoch):\n",
    "    callbacks_list = get_callback_list_by_model(model_name)\n",
    "#     train_proteins_shuffle, train_X_shuffle, train_y_shuffle = shuffle(train_proteins, train_X, train_y,random_state=randomS)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=[train_proteins,train_X], # create a list of inputs for embeddings\n",
    "            y=train_y, epochs=Epoch, \n",
    "            batch_size=64, verbose=1,\n",
    "            validation_data = ([valid_proteins,valid_X],valid_y),\n",
    "            callbacks=callbacks_list         \n",
    "               )\n",
    "\n",
    "    re=np.round(np.squeeze(model.predict([valid_proteins,valid_X])))\n",
    "    scroe(re,list(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_blocks(ft_number,k_size,input_tensor):\n",
    "    x = Conv1D(filters=ft_number, \n",
    "                     kernel_size=k_size, \n",
    "                     padding='same',\n",
    "                     kernel_regularizer=l2(l2_lambda)\n",
    "              )(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "#     x = Conv1D(filters=ft_number, \n",
    "#                      kernel_size=k_size, \n",
    "#                      padding='same',\n",
    "#                      kernel_regularizer=l2(l2_lambda)\n",
    "#               )(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "def op(inputs):\n",
    "    x, y = inputs\n",
    "    return K.pow((x - y), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_branch(init_input,kernel_size):\n",
    "    x=conv_blocks(ft_number=32,k_size=kernel_size,input_tensor=init_input)\n",
    "    x=MaxPooling1D(2,padding='same')(x)\n",
    "\n",
    "    x=conv_blocks(ft_number=64,k_size=kernel_size,input_tensor=x)\n",
    "    x=MaxPooling1D(2,padding='same')(x)\n",
    "\n",
    "    x=conv_blocks(ft_number=128,k_size=kernel_size,input_tensor=x)\n",
    "    u = GlobalMaxPooling1D()(x)\n",
    "    u_broadcast=RepeatVector(x.shape[1])(u)\n",
    "\n",
    "    o=Lambda(op)([u_broadcast,x])  # K.pow((x - y), 2) \n",
    "    var = GlobalAveragePooling1D()(o)\n",
    "    X_vector = concatenate([u,var])\n",
    "    return X_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lambda=0.05\n",
    "def create_multiBranch_Conv_model(Proeins_shape,Drags_shape):\n",
    "    \n",
    "    # left branch --> dimension reduction for Proeins_shape\n",
    "    \n",
    "    proeins_input_tensor = Input(shape=Proeins_shape, name='proeins_input_tensor')\n",
    "    init_input = Reshape((Proeins_shape[1], Proeins_shape[0]),input_shape=Proeins_shape,name='init_input')(proeins_input_tensor)\n",
    "\n",
    "    #branch 0\n",
    "    w=conv_branch(init_input,10)\n",
    "    #branch 1\n",
    "    x=conv_branch(init_input,5)\n",
    "\n",
    "    #branch 2\n",
    "    y=conv_branch(init_input,15)\n",
    "    \n",
    "    #branch 3\n",
    "    z=conv_branch(init_input,20)\n",
    "    \n",
    "    protein_concat = concatenate([w,x,y,z], name='protein_concat_')\n",
    "    \n",
    "    protein_dense = Dense(128)(protein_concat)\n",
    "    protein_dense = BatchNormalization()(protein_dense)\n",
    "    protein_dense = Activation('relu')(protein_dense)\n",
    "    protein_dense = Dropout(0.5)(protein_dense)\n",
    "    \n",
    "    \n",
    "    # right branch --> dimension reduction for drug/ligand\n",
    "    drag_input_tensor = Input(shape=(Drags_shape,),name='drag_input_tensor')\n",
    "    d = Dense(128)(drag_input_tensor)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Activation('relu')(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "\n",
    "    \n",
    "#     # merge the branches together\n",
    "    final_branch = concatenate([protein_dense,d], name='protein_darg_concat_')\n",
    "    \n",
    "    final_dense = Dense(64)(final_branch)\n",
    "    final_dense = BatchNormalization()(final_dense)\n",
    "    final_dense = Activation('relu')(final_dense)\n",
    "    final_dense = Dropout(0.5)(final_dense)\n",
    "\n",
    "#     final_dense = Dense(32)(final_dense)\n",
    "#     final_dense = BatchNormalization()(final_dense)\n",
    "#     final_dense = Activation('relu')(final_dense)\n",
    "#     final_dense = Dropout(0.5)(final_dense)\n",
    "    \n",
    "    final_output = Dense(1, activation='sigmoid', name='final_output')(final_dense)\n",
    "    \n",
    "#     model = Model(inputs=proeins_input_tensor, outputs=protein_concat)\n",
    "    model = Model(inputs=[proeins_input_tensor,drag_input_tensor], outputs=final_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22921 samples, validate on 22688 samples\n",
      "Epoch 1/20\n",
      "22921/22921 [==============================] - 120s 5ms/step - loss: 2.0221 - acc: 0.7862 - val_loss: 0.1645 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16451, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 2/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.1326 - acc: 0.8904 - val_loss: 0.1354 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16451 to 0.13540, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 3/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.1102 - acc: 0.9091 - val_loss: 0.1272 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13540 to 0.12724, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 4/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0966 - acc: 0.9224 - val_loss: 0.1221 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12724 to 0.12210, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 5/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0780 - acc: 0.9323 - val_loss: 0.1437 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12210\n",
      "Epoch 6/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0684 - acc: 0.9411 - val_loss: 0.2650 - val_acc: 0.6899\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12210\n",
      "Epoch 7/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0611 - acc: 0.9480 - val_loss: 0.0966 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12210 to 0.09661, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 8/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0560 - acc: 0.9528 - val_loss: 0.1057 - val_acc: 0.8759\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09661\n",
      "Epoch 9/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0462 - acc: 0.9551 - val_loss: 0.1156 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09661\n",
      "Epoch 10/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0423 - acc: 0.9603 - val_loss: 0.0926 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09661 to 0.09259, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 11/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0405 - acc: 0.9618 - val_loss: 0.0898 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09259 to 0.08982, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 12/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0390 - acc: 0.9645 - val_loss: 0.0957 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08982\n",
      "Epoch 13/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0325 - acc: 0.9682 - val_loss: 0.1001 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08982\n",
      "Epoch 14/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0329 - acc: 0.9691 - val_loss: 0.1336 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08982\n",
      "Epoch 15/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0286 - acc: 0.9723 - val_loss: 0.1158 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08982\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 16/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0219 - acc: 0.9764 - val_loss: 0.1736 - val_acc: 0.7912\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08982\n",
      "Epoch 17/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0208 - acc: 0.9767 - val_loss: 0.0943 - val_acc: 0.8828\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08982\n",
      "Epoch 18/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0187 - acc: 0.9791 - val_loss: 0.0790 - val_acc: 0.8985\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08982 to 0.07899, saving model to model_zoo/multiBranch_Conv_model.h5\n",
      "Epoch 19/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0185 - acc: 0.9799 - val_loss: 0.0832 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07899\n",
      "Epoch 20/20\n",
      "22921/22921 [==============================] - 102s 4ms/step - loss: 0.0177 - acc: 0.9812 - val_loss: 0.1280 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.95      0.82      8616\n",
      "        1.0       0.97      0.78      0.86     14072\n",
      "\n",
      "avg / total       0.87      0.85      0.85     22688\n",
      "\n",
      "[[ 8226   390]\n",
      " [ 3118 10954]]\n",
      "ACC: 0.8453808180535967\n"
     ]
    }
   ],
   "source": [
    "multiBranch_Conv_model = create_multiBranch_Conv_model(Proeins_shape,Drags_shape,)\n",
    "evaluate_model(multiBranch_Conv_model,'multiBranch_Conv_model',20)\n",
    "# SVG(model_to_dot(multiBranch_Conv_model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9648677735295843\n"
     ]
    }
   ],
   "source": [
    "multiBranch_Conv_model.load_weights('model_zoo/multiBranch_Conv_model.h5')\n",
    "re1 =np.squeeze(multiBranch_Conv_model.predict([valid_proteins,valid_X]))\n",
    "print (roc_auc_score(valid_y, re1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# reg=[0.001,0.01,0.1,0.05]\n",
    "# window_size_search=[[30,15,5],[30,30,30],[5,5,5],[10,10,10],[20,10,10],[20,20,20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_model_auc_byWindow(windows):\n",
    "#     Conv_model = create_Conv_model(Proeins_shape,Drags_shape,windows)\n",
    "#     evaluate_model(Conv_model,'Conv_model',20)\n",
    "#     Conv_model.load_weights('model_zoo/Conv_model.h5')\n",
    "#     re1 =np.squeeze(Conv_model.predict([valid_proteins,valid_X]))\n",
    "#     print (\"For Window\",windows, \"Reg is \",l2_lambda,roc_auc_score(valid_y, re1))\n",
    "#     result.append(roc_auc_score(valid_y, re1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in window_size_search:\n",
    "#     get_model_auc_byWindow(w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reresult = []\n",
    "# for R in reg:\n",
    "#     l2_lambda=R\n",
    "#     get_model_auc_byWindow([20,20,20])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
