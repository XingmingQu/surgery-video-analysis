{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import an awesome Label helper\n",
      "import an awesome feature helper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\razer\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import modules.labelHelper as lh \n",
    "import modules.featureHelper as fh\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Conv1D, GlobalAveragePooling1D, MaxPooling1D,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,average, concatenate,RepeatVector,Lambda,add,subtract,Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Input, Model\n",
    "from sklearn import metrics as mt\n",
    "from skimage.io import imshow\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "warnings.filterwarnings('ignore')\n",
    "from modules.modelTools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 videos in total\n",
      "\n",
      "There are 19 trainees in total\n",
      "\n",
      " Number of Videos from each person\n",
      "Akhtar          -- [176 253 761] ----: 3\n",
      "Cadeddu         -- [164 171] ----: 2\n",
      "Crivelli        -- [225 276 333 425] ----: 4\n",
      "Gahan           -- [257 345 378 384 486] ----: 5\n",
      "Johnson         -- [441 615] ----: 2\n",
      "Keith           -- [240 277 717] ----: 3\n",
      "Kenigsberg      -- [ 78 440 455 471 881] ----: 5\n",
      "Krabbe          -- [152 344 527 861] ----: 4\n",
      "Marthur         -- [130 194 222 368 921] ----: 5\n",
      "Mollengarden    -- [ 59 143 267 460] ----: 4\n",
      "Moony           -- [294 301 361 498 539] ----: 5\n",
      "Passoni         -- [207 237 895 942] ----: 4\n",
      "Rozanski        -- [113 302 716] ----: 3\n",
      "Satyanarayan    -- [ 16  74 236 358 436 457 503 537 557 578 599 632 689] ----: 13\n",
      "Singla          -- [ 49 536 538] ----: 3\n",
      "Sorokin         -- [ 91 226 507 530] ----: 4\n",
      "Timburlake      -- [258 296 559 742] ----: 4\n",
      "Tse             -- [ 11 283 414 427 562 928] ----: 6\n",
      "Varun           -- [192 401 417 820] ----: 4\n",
      "train on videos from:\n",
      " ['Mollengarden', 'Moony', 'Sorokin', 'Keith', 'Akhtar', 'Varun', 'Cadeddu', 'Johnson', 'Passoni', 'Krabbe', 'Gahan', 'Singla', 'Rozanski', 'Crivelli', 'Marthur']\n",
      "test on videos from:\n",
      " ['Timburlake', 'Satyanarayan', 'Kenigsberg', 'Tse']\n",
      "[ 59 143 267 460 294 301 361 498 539  91 226 507 530 240 277 717 176 253\n",
      " 761 192 401 417 820 164 171 441 615 207 237 895 942 152 344 527 861 257\n",
      " 345 378 384 486  49 536 538 113 302 716 225 276 333 425 130 194 222 368\n",
      " 921]\n",
      "[258 296 559 742  16  74 236 358 436 457 503 537 557 578 599 632 689  78\n",
      " 440 455 471 881  11 283 414 427 562 928]\n",
      "load feature from files, there are 55 videos\n",
      "after deop:  55\n",
      "load feature from files, there are 28 videos\n",
      "after deop:  28\n",
      "(1726, 30, 28)\n",
      "(1726, 6)\n",
      "(976, 30, 28)\n",
      "(976, 6)\n"
     ]
    }
   ],
   "source": [
    "ll=lh.Label('..//2019_fall_labels.csv')\n",
    "print(\"There are %d videos in total\\n\"%ll.video_count())\n",
    "ll.get_trainee_info()\n",
    "\n",
    "train_video_number,test_video_number=ll.train_test_split_on_people(0.2)\n",
    "print(train_video_number)\n",
    "print(test_video_number)\n",
    "\n",
    "## set up feature parameters ##\n",
    "folder = \"C:\\\\2019_fall_video_features\"\n",
    "video_clips_length=30\n",
    "time_lag=2\n",
    "move_threshold=150\n",
    "stride=video_clips_length\n",
    "\n",
    "\n",
    "# train test split by people\n",
    "train_video,train_video_label=fh.make_train_test_data_from_video_numbers(folder,train_video_number,video_clips_length,time_lag,move_threshold,stride,ll)\n",
    "test_video,test_video_label=fh.make_train_test_data_from_video_numbers(folder,test_video_number,video_clips_length,time_lag,move_threshold,stride,ll)\n",
    "print(train_video.shape)\n",
    "print(train_video_label.shape)\n",
    "print(test_video.shape)\n",
    "print(test_video_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lambda=0.01\n",
    "model=make_model(0.01,30,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26/26 [==============================] - 8s 294ms/step - loss: 0.7588 - DP_loss: 0.1055 - BD_loss: 0.0863 - E_loss: 0.1064 - FS_loss: 0.1134 - A_loss: 0.1844 - RC_loss: 0.0943 - val_loss: 0.7166 - val_DP_loss: 0.0854 - val_BD_loss: 0.0688 - val_E_loss: 0.1164 - val_FS_loss: 0.0988 - val_A_loss: 0.1471 - val_RC_loss: 0.1317\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71656, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 2/30\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6084 - DP_loss: 0.0732 - BD_loss: 0.0741 - E_loss: 0.0853 - FS_loss: 0.0873 - A_loss: 0.1433 - RC_loss: 0.0771 - val_loss: 0.6450 - val_DP_loss: 0.0887 - val_BD_loss: 0.0757 - val_E_loss: 0.1257 - val_FS_loss: 0.0828 - val_A_loss: 0.0919 - val_RC_loss: 0.1122\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71656 to 0.64503, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 3/30\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.5057 - DP_loss: 0.0578 - BD_loss: 0.0662 - E_loss: 0.0735 - FS_loss: 0.0711 - A_loss: 0.1047 - RC_loss: 0.0647 - val_loss: 0.5810 - val_DP_loss: 0.0812 - val_BD_loss: 0.0598 - val_E_loss: 0.1293 - val_FS_loss: 0.0782 - val_A_loss: 0.0711 - val_RC_loss: 0.0941\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64503 to 0.58102, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 4/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4551 - DP_loss: 0.0512 - BD_loss: 0.0650 - E_loss: 0.0635 - FS_loss: 0.0644 - A_loss: 0.0854 - RC_loss: 0.0586 - val_loss: 0.6505 - val_DP_loss: 0.1004 - val_BD_loss: 0.0762 - val_E_loss: 0.1397 - val_FS_loss: 0.0798 - val_A_loss: 0.0703 - val_RC_loss: 0.1175\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.58102\n",
      "Epoch 5/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4110 - DP_loss: 0.0429 - BD_loss: 0.0585 - E_loss: 0.0625 - FS_loss: 0.0579 - A_loss: 0.0712 - RC_loss: 0.0517 - val_loss: 0.6978 - val_DP_loss: 0.1126 - val_BD_loss: 0.0755 - val_E_loss: 0.1341 - val_FS_loss: 0.0990 - val_A_loss: 0.0765 - val_RC_loss: 0.1340\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.58102\n",
      "Epoch 6/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3847 - DP_loss: 0.0399 - BD_loss: 0.0587 - E_loss: 0.0577 - FS_loss: 0.0524 - A_loss: 0.0587 - RC_loss: 0.0516 - val_loss: 0.5864 - val_DP_loss: 0.0971 - val_BD_loss: 0.0615 - val_E_loss: 0.0945 - val_FS_loss: 0.0848 - val_A_loss: 0.0721 - val_RC_loss: 0.1112\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.58102\n",
      "Epoch 7/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3765 - DP_loss: 0.0377 - BD_loss: 0.0585 - E_loss: 0.0569 - FS_loss: 0.0540 - A_loss: 0.0548 - RC_loss: 0.0496 - val_loss: 0.5933 - val_DP_loss: 0.0998 - val_BD_loss: 0.0617 - val_E_loss: 0.1001 - val_FS_loss: 0.0815 - val_A_loss: 0.0811 - val_RC_loss: 0.1044\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.58102\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/30\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3568 - DP_loss: 0.0363 - BD_loss: 0.0528 - E_loss: 0.0525 - FS_loss: 0.0491 - A_loss: 0.0535 - RC_loss: 0.0481 - val_loss: 0.6053 - val_DP_loss: 0.1057 - val_BD_loss: 0.0651 - val_E_loss: 0.1027 - val_FS_loss: 0.0888 - val_A_loss: 0.0798 - val_RC_loss: 0.0990\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58102\n",
      "Epoch 9/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3456 - DP_loss: 0.0368 - BD_loss: 0.0519 - E_loss: 0.0493 - FS_loss: 0.0476 - A_loss: 0.0494 - RC_loss: 0.0464 - val_loss: 0.6506 - val_DP_loss: 0.1050 - val_BD_loss: 0.0687 - val_E_loss: 0.1172 - val_FS_loss: 0.1006 - val_A_loss: 0.0908 - val_RC_loss: 0.1045\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58102\n",
      "Epoch 10/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3290 - DP_loss: 0.0346 - BD_loss: 0.0484 - E_loss: 0.0460 - FS_loss: 0.0461 - A_loss: 0.0455 - RC_loss: 0.0447 - val_loss: 0.5810 - val_DP_loss: 0.0955 - val_BD_loss: 0.0599 - val_E_loss: 0.1012 - val_FS_loss: 0.0835 - val_A_loss: 0.0846 - val_RC_loss: 0.0928\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.58102 to 0.58100, saving model to model_zoo/MTmodel.h5\n",
      "Epoch 11/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3317 - DP_loss: 0.0344 - BD_loss: 0.0503 - E_loss: 0.0499 - FS_loss: 0.0478 - A_loss: 0.0421 - RC_loss: 0.0439 - val_loss: 0.6945 - val_DP_loss: 0.1103 - val_BD_loss: 0.0760 - val_E_loss: 0.1290 - val_FS_loss: 0.1025 - val_A_loss: 0.0962 - val_RC_loss: 0.1175\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.58100\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/30\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3196 - DP_loss: 0.0332 - BD_loss: 0.0489 - E_loss: 0.0465 - FS_loss: 0.0438 - A_loss: 0.0420 - RC_loss: 0.0423 - val_loss: 0.6470 - val_DP_loss: 0.1063 - val_BD_loss: 0.0699 - val_E_loss: 0.1184 - val_FS_loss: 0.0899 - val_A_loss: 0.0913 - val_RC_loss: 0.1083\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.58100\n",
      "Epoch 13/30\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3177 - DP_loss: 0.0315 - BD_loss: 0.0460 - E_loss: 0.0442 - FS_loss: 0.0449 - A_loss: 0.0452 - RC_loss: 0.0433 - val_loss: 0.6418 - val_DP_loss: 0.1011 - val_BD_loss: 0.0657 - val_E_loss: 0.1193 - val_FS_loss: 0.0917 - val_A_loss: 0.0934 - val_RC_loss: 0.1080\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.58100\n",
      "Epoch 14/30\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3149 - DP_loss: 0.0347 - BD_loss: 0.0470 - E_loss: 0.0456 - FS_loss: 0.0425 - A_loss: 0.0418 - RC_loss: 0.0408 - val_loss: 0.6274 - val_DP_loss: 0.1006 - val_BD_loss: 0.0667 - val_E_loss: 0.1192 - val_FS_loss: 0.0898 - val_A_loss: 0.0872 - val_RC_loss: 0.1015\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.58100\n",
      "Epoch 15/30\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3167 - DP_loss: 0.0320 - BD_loss: 0.0503 - E_loss: 0.0450 - FS_loss: 0.0436 - A_loss: 0.0428 - RC_loss: 0.0406 - val_loss: 0.6175 - val_DP_loss: 0.0971 - val_BD_loss: 0.0657 - val_E_loss: 0.1109 - val_FS_loss: 0.0902 - val_A_loss: 0.0882 - val_RC_loss: 0.1032\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.58100\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/30\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3055 - DP_loss: 0.0317 - BD_loss: 0.0445 - E_loss: 0.0437 - FS_loss: 0.0433 - A_loss: 0.0402 - RC_loss: 0.0399 - val_loss: 0.6543 - val_DP_loss: 0.0995 - val_BD_loss: 0.0714 - val_E_loss: 0.1194 - val_FS_loss: 0.0985 - val_A_loss: 0.0950 - val_RC_loss: 0.1085\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.58100\n",
      "Epoch 17/30\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3084 - DP_loss: 0.0322 - BD_loss: 0.0457 - E_loss: 0.0430 - FS_loss: 0.0436 - A_loss: 0.0409 - RC_loss: 0.0409 - val_loss: 0.6459 - val_DP_loss: 0.0990 - val_BD_loss: 0.0706 - val_E_loss: 0.1174 - val_FS_loss: 0.0951 - val_A_loss: 0.0927 - val_RC_loss: 0.1091\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.58100\n"
     ]
    }
   ],
   "source": [
    "X_train=train_video/640-0.5\n",
    "X_test=test_video/640-0.5\n",
    "y_train=train_video_label/5\n",
    "y_test=test_video_label/5\n",
    "#     y_train=y_train\n",
    "#     y_test=y_test\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print(X_test.shape,y_test.shape)\n",
    "\n",
    "sample_of_trainningdata=X_train.shape[0]\n",
    "sample_of_testdata=X_test.shape[0]\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_gen=generator(X_train, y_train, batch_size,0.1)\n",
    "val_gen=generator(X_test, y_test, batch_size,0)\n",
    "\n",
    "#prepare for inout shape\n",
    "clip_lenth=X_train.shape[1]\n",
    "dimension=X_train.shape[2]\n",
    "\n",
    "callbacks_list = get_callback_list_by_model('MTmodel')\n",
    "model_h=model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=sample_of_trainningdata//batch_size,\n",
    "                    epochs=30,\n",
    "                    validation_data=val_gen,\n",
    "                   validation_steps=sample_of_testdata//batch_size +1 ,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks_list\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks_list = get_callback_list_by_model(\"mtmodel\")\n",
    "# #     train_proteins_shuffle, train_X_shuffle, train_y_shuffle = shuffle(train_proteins, train_X, train_y,random_state=randomS)\n",
    "\n",
    "\n",
    "# model.fit(x=train_video, # create a list of inputs for embeddings\n",
    "#         y=train_video_label, epochs=10, \n",
    "#         batch_size=64, verbose=1,\n",
    "\n",
    "#         callbacks=callbacks_list         \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re=model.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(re[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_gen=generator(train_video, train_video_label, 32,0.1)\n",
    "# a,b=next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
